{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyP1G9r0kDO2"
   },
   "source": [
    "# Incremental margin algorithm for large margin classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N1mMqyF5kDO6"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_digits\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "from numpy import linalg as LA\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1YAuDbBkDO-"
   },
   "source": [
    "## Calculating the margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eZvyTFl_kDO_"
   },
   "outputs": [],
   "source": [
    "def compute_margin(X, y, w, b):\n",
    "    margin = []\n",
    "    for i in range(y.shape[0]):\n",
    "        margin.append((y[i]*(np.dot(X[i,:], w)+b))/sqrt(sum(w**2))) \n",
    "    if min(margin) >= 0:\n",
    "        return min(margin)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L0 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L0_norm(w, threshold):\n",
    "    l0_norm = 0\n",
    "    for wi in w:\n",
    "        if abs(wi) > threshold:\n",
    "            l0_norm += 1\n",
    "    return l0_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mQ-uGN3kDPB"
   },
   "source": [
    "# ELM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBc5s_nkkDPB"
   },
   "source": [
    "## ELM with IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class IM_ELM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    # Inicialization of important parameters \n",
    "    def __init__(self, n_neurons, eta=0.1, lambda_param=0.01, delta_margin=10^-3,\n",
    "                 IMA_iterations=10, max_updates=10000):\n",
    "        self.n_neurons = n_neurons              # Neurons of hidden layer osf ELM\n",
    "        self.eta = eta                          # Learning rate\n",
    "        self.lambda_param = lambda_param        # Param important of soft margin\n",
    "        self.delta_margin = delta_margin        # (1 + delta_margin) * fixed margin defines the minimum next margin of IMA\n",
    "        self.IMA_iterations = IMA_iterations    # Maximum number of iterations of IMA\n",
    "        self.max_updates = max_updates          # Maximum number of updates in one execution of FMP\n",
    "        self.w = np.array([])                   # Vector of weights of the last layer of the ELM obtained after the training of the IMA\n",
    "        self.w_elm = np.array([])               # Vector of weights of the last layer of the ELM obtained after the normal training of ELM\n",
    "        self.H = np.array([])                   # H matrix of ELM (obtained with training data)\n",
    "        self.Z = np.array([])                   # Z matrix of ELM\n",
    "        self.b = 0\n",
    "\n",
    "    # Fixed Margin Algorithm    \n",
    "    def FMP_algorithm(self, X, y, w_init, b_init, fixed_margin, idx, s):\n",
    "        t = 0\n",
    "        iterations = 0\n",
    "        w = w_init\n",
    "        b = b_init\n",
    "        norm_w = sqrt(sum(w**2))\n",
    "        last_t = -1\n",
    "        lambda_t = 0\n",
    "        alpha = np.zeros((X.shape[0]))\n",
    "        while True:\n",
    "            last_t = t\n",
    "            e=0\n",
    "            for k in range(0, y.shape[0]):\n",
    "                i = int(idx[k])\n",
    "                if(y[i]*(np.dot(X[i,:], w)+b) <= fixed_margin * norm_w - self.lambda_param * alpha[i]):\n",
    "                    if norm_w != 0:\n",
    "                        lambda_t = 1 - (self.eta*fixed_margin)/norm_w\n",
    "                    else:\n",
    "                        lambda_t = 1\n",
    "                    alpha = alpha * lambda_t\n",
    "                    alpha[i] = alpha[i] + self.eta    \n",
    "                    w = w * lambda_t + self.eta * y[i] * X[i,:]\n",
    "                    norm_w = sqrt(sum(w**2))\n",
    "                    b = b + self.eta*y[i]\n",
    "                    t += 1\n",
    "                    e += 1\n",
    "                    if k > s:\n",
    "                        s += 1\n",
    "                        j = s\n",
    "                    else:\n",
    "                        j=e\n",
    "                    idx[k], idx[j] = idx[j], idx[k]\n",
    "            iterations += 1\n",
    "            if (t > self.max_updates or last_t == t):\n",
    "                break\n",
    "        if t<= self.max_updates:\n",
    "            convergence=1\n",
    "        else:\n",
    "            convergence=0\n",
    "        return w, b, convergence, t, iterations, idx, s\n",
    "\n",
    "    # IMA Algorithm\n",
    "    def IM_algorithm(self, X, y):\n",
    "        self.w = np.zeros(self.w_elm.shape[0])\n",
    "        self.ws = [] \n",
    "        self.bs = [] \n",
    "        self.ws.append(self.w)\n",
    "        self.bs.append(self.b)\n",
    "        fixed_margin = 0#compute_margin(X, y, self.w_elm, self.b)\n",
    "        t = 0\n",
    "        convergence = 1\n",
    "        updates=0\n",
    "        iterations=0\n",
    "        margin=[]\n",
    "        margin.append(fixed_margin)\n",
    "        idx = np.linspace(0, y.shape[0]-1, y.shape[0])\n",
    "        s=0\n",
    "        while convergence==1 and t<self.IMA_iterations:\n",
    "            w, b, convergence, updates_, iterations_, idx, s = self.FMP_algorithm(X, y, self.w, self.b, fixed_margin, idx, s)\n",
    "            if convergence == 1:\n",
    "                self.w = w\n",
    "                self.b = b\n",
    "                self.ws.append(self.w)\n",
    "                self.bs.append(self.b)\n",
    "            updates += updates_\n",
    "            iterations += iterations_\n",
    "            norm_w = sqrt(sum(self.w**2))\n",
    "            gamma1 = []\n",
    "            gamma2 = []\n",
    "            for i in range(0, y.shape[0]):\n",
    "                if y[i] == 1:\n",
    "                    gamma1.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "                else:\n",
    "                    gamma2.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "            gamma1 = np.array(gamma1)\n",
    "            gamma2 = np.array(gamma2)\n",
    "            gamma1 = gamma1[gamma1>=0]\n",
    "            gamma2 = gamma2[gamma2>=0]\n",
    "            if len(gamma1) == 0:\n",
    "                min_gamma1 = 0\n",
    "            else:\n",
    "                min_gamma1 = min(gamma1)\n",
    "            if len(gamma2) == 0:\n",
    "                min_gamma2 = 0\n",
    "            else:\n",
    "                min_gamma2 = min(gamma2)\n",
    "            fixed_margin = max([(min_gamma1 + min_gamma2)/2, (1+self.delta_margin)*fixed_margin])\n",
    "            margin.append(compute_margin(X, y, self.w, self.b))\n",
    "            t += 1\n",
    "        return t, updates, iterations, margin\n",
    "\n",
    "    # Function that manage the training of IMA ELM\n",
    "    def fit(self, X, y):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        X = X_new\n",
    "        n = X.shape[1]\n",
    "        self.Z = np.array([random.uniform(-0.5, 0.5) for i in range(n*self.n_neurons)]).reshape(n, self.n_neurons)\n",
    "        self.H = np.tanh(np.dot(X, self.Z))\n",
    "        w = np.dot(np.linalg.pinv(self.H), y)  \n",
    "        self.w_elm = w.reshape((w.shape[0],))\n",
    "        iterations_IMA, updates, iterations, margin = self.IM_algorithm(self.H, y) \n",
    "        return iterations_IMA, updates, iterations, margin\n",
    "            \n",
    "    # Function to apply IMA ELM model\n",
    "    def predict(self, X, use_IMA_w=True):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        if use_IMA_w == True:\n",
    "            y_predicted = np.sign(np.dot(H, self.w) + self.b)\n",
    "        else:\n",
    "            y_predicted = np.sign(np.dot(H,  self.w_elm))\n",
    "        y_predicted[y_predicted==0]=-1\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELM with IM P 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IM_ELM_p1(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    # Inicialization of important parameters \n",
    "    def __init__(self, n_neurons, eta=0.1, lambda_param=0.01, delta_margin=10^-8,\n",
    "                 IMA_iterations=10, max_updates=10000):\n",
    "        self.n_neurons = n_neurons              # Neurons of hidden layer osf ELM\n",
    "        self.eta = eta                          # Learning rate\n",
    "        self.lambda_param = lambda_param        # Param important of soft margin\n",
    "        self.delta_margin = delta_margin        # (1 + delta_margin) * fixed margin defines the minimum next margin of IMA\n",
    "        self.IMA_iterations = IMA_iterations    # Maximum number of iterations of IMA\n",
    "        self.max_updates = max_updates          # Maximum number of updates in one execution of FMP\n",
    "        self.w = np.array([])                   # Vector of weights of the last layer of the ELM obtained after the training of the IMA\n",
    "        self.w_elm = np.array([])               # Vector of weights of the last layer of the ELM obtained after the normal training of ELM\n",
    "        self.H = np.array([])                   # H matrix of ELM (obtained with training data)\n",
    "        self.Z = np.array([])                   # Z matrix of ELM\n",
    "        self.b = 0\n",
    "\n",
    "    # Fixed Margin Algorithm    \n",
    "    def FMP_algorithm(self, X, y, w_init, b_init, fixed_margin, idx, s):\n",
    "        t = 0\n",
    "        iterations = 0\n",
    "        w = w_init\n",
    "        b = b_init\n",
    "        w_norm_inf = LA.norm(w, ord=np.inf)\n",
    "        last_t = -1\n",
    "        lambda_t = 0\n",
    "        alpha = np.zeros((X.shape[0]))\n",
    "        while True:\n",
    "            last_t = t\n",
    "            e=0\n",
    "            for k in range(0, y.shape[0]):\n",
    "                i = int(idx[k])\n",
    "                if(y[i]*(np.dot(X[i,:], w)+b) <= fixed_margin * w_norm_inf - self.lambda_param * alpha[i]):\n",
    "                    if w_norm_inf != 0:\n",
    "                        lambda_t = 1 - (self.eta*fixed_margin)/w_norm_inf\n",
    "                    else:\n",
    "                        lambda_t = 1\n",
    "                    alpha = alpha * lambda_t\n",
    "                    alpha[i] = alpha[i] + self.eta    \n",
    "                    for j in range(len(w)):\n",
    "                        if abs(w[j]) == w_norm_inf:\n",
    "                            w[j] = w[j] - self.eta * (fixed_margin * np.sign(w[j])/sum(abs(w) == w_norm_inf) - y[i] * X[i,j])\n",
    "                        elif abs(w[j]) < w_norm_inf:\n",
    "                            w[j] = w[j] + self.eta * (y[i] * X[i,j])\n",
    "                    w_norm_inf = LA.norm(w, ord=np.inf)\n",
    "                    b = b + self.eta*y[i]\n",
    "                    t += 1\n",
    "                    e += 1\n",
    "                    if k > s:\n",
    "                        s += 1\n",
    "                        j = s\n",
    "                    else:\n",
    "                        j=e\n",
    "                    idx[k], idx[j] = idx[j], idx[k]\n",
    "            iterations += 1\n",
    "            if (t > self.max_updates or last_t == t):\n",
    "                break\n",
    "        if t<= self.max_updates:\n",
    "            convergence=1\n",
    "        else:\n",
    "            convergence=0\n",
    "        return w, b, convergence, t, iterations, idx, s\n",
    "\n",
    "    # IMA Algorithm\n",
    "    def IM_algorithm(self, X, y):\n",
    "        self.w = np.zeros(self.H.shape[1])\n",
    "        w = deepcopy(self.w)\n",
    "        fixed_margin = 0#compute_margin(X, y, self.w, self.b)\n",
    "        t = 0\n",
    "        convergence = 1\n",
    "        updates=0\n",
    "        iterations=0\n",
    "        margin=[]\n",
    "        l = 0\n",
    "        idx = np.linspace(0, y.shape[0]-1, y.shape[0])\n",
    "        s=0\n",
    "        while convergence==1 and t<self.IMA_iterations:\n",
    "            w, b, convergence, updates_, iterations_, idx, s = self.FMP_algorithm(X, y, w, self.b, fixed_margin, idx, s)\n",
    "            if convergence == 1:\n",
    "                self.w = w\n",
    "                self.b = b\n",
    "            updates += updates_\n",
    "            iterations += iterations_\n",
    "            norm_w = LA.norm(w, ord=np.inf)\n",
    "            gamma1 = []\n",
    "            gamma2 = []\n",
    "            for i in range(0, y.shape[0]):\n",
    "                if y[i] == 1:\n",
    "                    gamma1.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "                else:\n",
    "                    gamma2.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "            if max(gamma1) < 0:\n",
    "                gamma1.append(0)\n",
    "            if max(gamma2) < 0:\n",
    "                gamma2.append(0)\n",
    "            gamma1 = np.array(gamma1)\n",
    "            gamma2 = np.array(gamma2)\n",
    "            gamma1 = gamma1[gamma1>=0]\n",
    "            gamma2 = gamma2[gamma2>=0]\n",
    "            if len(gamma1) == 0:\n",
    "                min_gamma1 = 0\n",
    "            else:\n",
    "                min_gamma1 = min(gamma1)\n",
    "            if len(gamma2) == 0:\n",
    "                min_gamma2 = 0\n",
    "            else:\n",
    "                min_gamma2 = min(gamma2)\n",
    "            fixed_margin = max([(min_gamma1 + min_gamma2)/2, (1+self.delta_margin)*fixed_margin])\n",
    "            #margin.append(compute_margin(X, y, self.w, self.b))\n",
    "            t += 1\n",
    "        return t, updates, iterations, margin\n",
    "\n",
    "    # Function that manage the training of IMA ELM\n",
    "    def fit(self, X, y, Z=[]):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        X = X_new\n",
    "        n = X.shape[1]\n",
    "        if len(Z) == 0:\n",
    "            self.Z = np.array([random.uniform(-0.5, 0.5) for i in range(n*self.n_neurons)]).reshape(n, self.n_neurons)\n",
    "        else:\n",
    "            self.Z = Z\n",
    "        self.H = np.tanh(np.dot(X, self.Z))\n",
    "        #w = np.dot(np.linalg.pinv(self.H), y)  \n",
    "        #self.w_elm = w.reshape((w.shape[0],))\n",
    "        iterations_IMA, updates, iterations, margin = self.IM_algorithm(self.H, y) \n",
    "        return iterations_IMA, updates, iterations, margin\n",
    "            \n",
    "    # Function to apply IMA ELM model\n",
    "    def predict(self, X, use_IMA_w=True):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        if use_IMA_w == True:\n",
    "            y_predicted = np.sign(np.dot(H, self.w) + self.b)\n",
    "        else:\n",
    "            y_predicted = np.sign(np.dot(H,  self.w_elm))\n",
    "        y_predicted[y_predicted==0]=-1\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELM with IM P inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IM_ELM_pinf(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    # Inicialization of important parameters \n",
    "    def __init__(self, n_neurons, eta=0.1, lambda_param=0.01, delta_margin=10^-3,\n",
    "                 IMA_iterations=10, max_updates=10000):\n",
    "        self.n_neurons = n_neurons              # Neurons of hidden layer osf ELM\n",
    "        self.eta = eta                          # Learning rate\n",
    "        self.lambda_param = lambda_param        # Param important of soft margin\n",
    "        self.delta_margin = delta_margin        # (1 + delta_margin) * fixed margin defines the minimum next margin of IMA\n",
    "        self.IMA_iterations = IMA_iterations    # Maximum number of iterations of IMA\n",
    "        self.max_updates = max_updates          # Maximum number of updates in one execution of FMP\n",
    "        self.w = np.array([])                   # Vector of weights of the last layer of the ELM obtained after the training of the IMA\n",
    "        self.w_elm = np.array([])               # Vector of weights of the last layer of the ELM obtained after the normal training of ELM\n",
    "        self.H = np.array([])                   # H matrix of ELM (obtained with training data)\n",
    "        self.Z = np.array([])                   # Z matrix of ELM\n",
    "        self.b = 0\n",
    "\n",
    "    # Fixed Margin Algorithm    \n",
    "    def FMP_algorithm(self, X, y, w_init, b_init, fixed_margin, idx, s):\n",
    "        t = 0\n",
    "        iterations = 0\n",
    "        w = w_init\n",
    "        b = b_init\n",
    "        w_norm_1 = LA.norm(w, ord=1)\n",
    "        last_t = -1\n",
    "        lambda_t = 0\n",
    "        alpha = np.zeros((X.shape[0]))\n",
    "        while True:\n",
    "            last_t = t\n",
    "            e=0\n",
    "            for k in range(0, y.shape[0]):\n",
    "                i = int(idx[k])\n",
    "                if(y[i]*(np.dot(X[i,:], w)+b) <= fixed_margin * w_norm_1 - self.lambda_param * alpha[i]):\n",
    "                    if w_norm_1 != 0:\n",
    "                        lambda_t = 1 - (self.eta*fixed_margin)/w_norm_1\n",
    "                    else:\n",
    "                        lambda_t = 1\n",
    "                    alpha = alpha * lambda_t\n",
    "                    alpha[i] = alpha[i] + self.eta    \n",
    "                    w = w - self.eta * (fixed_margin * np.sign(w) - y[i] * X[i,:])\n",
    "                    w_norm_1 = LA.norm(w, ord=1)\n",
    "                    b = b + self.eta*y[i]\n",
    "                    t += 1\n",
    "                    e += 1\n",
    "                    if k > s:\n",
    "                        s += 1\n",
    "                        j = s\n",
    "                    else:\n",
    "                        j=e\n",
    "                    idx[k], idx[j] = idx[j], idx[k]\n",
    "            iterations += 1\n",
    "            if (t > self.max_updates or last_t == t):\n",
    "                break\n",
    "        if t<= self.max_updates:\n",
    "            convergence=1\n",
    "        else:\n",
    "            convergence=0\n",
    "        return w, b, convergence, t, iterations, idx, s\n",
    "\n",
    "    # IMA Algorithm\n",
    "    def IM_algorithm(self, X, y):\n",
    "        self.w = np.zeros(self.H.shape[1])\n",
    "        self.ws = [] \n",
    "        self.bs = [] \n",
    "        self.ws.append(self.w)\n",
    "        self.bs.append(self.b)\n",
    "        fixed_margin = 0#compute_margin(X, y, self.w_elm, self.b)\n",
    "        t = 0\n",
    "        convergence = 1\n",
    "        updates=0\n",
    "        iterations=0\n",
    "        margin=[]\n",
    "        margin.append(fixed_margin)\n",
    "        idx = np.linspace(0, y.shape[0]-1, y.shape[0])\n",
    "        s=0\n",
    "        l=0\n",
    "        while convergence==1 and t<self.IMA_iterations:\n",
    "            w, b, convergence, updates_, iterations_, idx, s = self.FMP_algorithm(X, y, self.w, self.b, fixed_margin, idx, s)\n",
    "            if convergence == 1:\n",
    "                self.w = w\n",
    "                self.b = b\n",
    "                self.ws.append(self.w)\n",
    "                self.bs.append(self.b)\n",
    "            updates += updates_\n",
    "            iterations += iterations_\n",
    "            norm_w = LA.norm(w, ord=1)\n",
    "            gamma1 = []\n",
    "            gamma2 = []\n",
    "            for i in range(0, y.shape[0]):\n",
    "                if y[i] == 1:\n",
    "                    gamma1.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "                else:\n",
    "                    gamma2.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "            gamma1 = np.array(gamma1)\n",
    "            gamma2 = np.array(gamma2)\n",
    "            gamma1 = gamma1[gamma1>=0]\n",
    "            gamma2 = gamma2[gamma2>=0]\n",
    "            if len(gamma1) == 0:\n",
    "                min_gamma1 = 0\n",
    "            else:\n",
    "                min_gamma1 = min(gamma1)\n",
    "            if len(gamma2) == 0:\n",
    "                min_gamma2 = 0\n",
    "            else:\n",
    "                min_gamma2 = min(gamma2)\n",
    "            fixed_margin = max([(min_gamma1 + min_gamma2)/2, (1+self.delta_margin)*fixed_margin])\n",
    "            #margin.append(compute_margin(X, y, self.w, self.b))\n",
    "            t += 1\n",
    "        return t, updates, iterations, margin\n",
    "\n",
    "    # Function that manage the training of IMA ELM\n",
    "    def fit(self, X, y, Z=[]):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        X = X_new\n",
    "        n = X.shape[1]\n",
    "        if len(Z) == 0:\n",
    "            self.Z = np.array([random.uniform(-0.5, 0.5) for i in range(n*self.n_neurons)]).reshape(n, self.n_neurons)\n",
    "        else:\n",
    "            self.Z = Z\n",
    "        self.H = np.tanh(np.dot(X, self.Z))\n",
    "        #w = np.dot(np.linalg.pinv(self.H), y)  \n",
    "        #self.w_elm = w.reshape((w.shape[0],))\n",
    "        iterations_IMA, updates, iterations, margin = self.IM_algorithm(self.H, y) \n",
    "        return iterations_IMA, updates, iterations, margin\n",
    "            \n",
    "    # Function to apply IMA ELM model\n",
    "    def predict(self, X, use_IMA_w=True):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        if use_IMA_w == True:\n",
    "            y_predicted = np.sign(np.dot(H, self.w) + self.b)\n",
    "        else:\n",
    "            y_predicted = np.sign(np.dot(H,  self.w_elm))\n",
    "        y_predicted[y_predicted==0]=-1\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGgtVO-SkDPH"
   },
   "source": [
    "## Commom ELM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hQdXLRz_kDPI"
   },
   "outputs": [],
   "source": [
    "class ELM(BaseEstimator, ClassifierMixin):\n",
    "         \n",
    "    def __init__(self, n_neurons):\n",
    "        self.n_neurons = n_neurons\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Adding polarization term \n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        n = X_new.shape[1]\n",
    "        self.Z = np.array([random.uniform(-0.5, 0.5) for i in range(n*self.n_neurons)]).reshape(n, self.n_neurons)\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        self.w = np.dot(np.linalg.pinv(H), y)           \n",
    "        return self.w, H, self.Z\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        y_predicted = np.sign(np.dot(H, self.w))\n",
    "        y_predicted[y_predicted==0]=1\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Capture Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(X, y, n_splits, p, eta, IMA_iterations):  \n",
    "    # Normalizing data:\n",
    "    normalizer = MinMaxScaler()\n",
    "    X = normalizer.fit_transform(X)\n",
    "    \n",
    "    # GridSearch for lambda and learning rate of IMA ELM\n",
    "    parameters = {'lambda_param':np.linspace(0.01, 10, 50)}\n",
    "    clf = IM_ELM(n_neurons=p, delta_margin=10^-3, IMA_iterations=10, max_updates=10000)\n",
    "    clf = GridSearchCV(clf, parameters, scoring='accuracy', cv=5, verbose=0)\n",
    "    clf.fit(X, y)\n",
    "    lambda_param = clf.best_params_['lambda_param']\n",
    "         \n",
    "    print(f'Parameters: p={p}, eta={eta}, lambda={lambda_param}')\n",
    "    # Stratified k fold cross validation\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=72)\n",
    "    i=0\n",
    "\n",
    "    train_accuracy_IM_ELM = np.zeros(n_splits)\n",
    "    test_accuracy_IM_ELM = np.zeros(n_splits)\n",
    "    margin_IM_ELM = np.zeros(n_splits)\n",
    "    updates = np.zeros(n_splits)\n",
    "    iterations_FMP = np.zeros(n_splits) \n",
    "    iterations_IMA = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_0 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_4 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_5 = np.zeros(n_splits)\n",
    "\n",
    "    train_accuracy_IM_ELM_p1 = np.zeros(n_splits)\n",
    "    test_accuracy_IM_ELM_p1 = np.zeros(n_splits)\n",
    "    margin_IM_ELM_p1 = np.zeros(n_splits)\n",
    "    updates_p1 = np.zeros(n_splits)\n",
    "    iterations_FMP_p1 = np.zeros(n_splits) \n",
    "    iterations_IMA_p1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_0 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_4 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_p1_5 = np.zeros(n_splits)\n",
    "    \n",
    "    train_accuracy_IM_ELM_pinf = np.zeros(n_splits)\n",
    "    test_accuracy_IM_ELM_pinf = np.zeros(n_splits)\n",
    "    margin_IM_ELM_pinf = np.zeros(n_splits)\n",
    "    updates_pinf = np.zeros(n_splits)\n",
    "    iterations_FMP_pinf = np.zeros(n_splits) \n",
    "    iterations_IMA_pinf = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_0 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_4 = np.zeros(n_splits)\n",
    "    norm_L0_IM_ELM_pinf_5 = np.zeros(n_splits)\n",
    "    \n",
    "    train_accuracy_ELM = np.zeros(n_splits)\n",
    "    test_accuracy_ELM = np.zeros(n_splits)\n",
    "    margin_ELM = np.zeros(n_splits)\n",
    "    norm_L0_ELM = np.zeros(n_splits)\n",
    "    norm_L0_ELM_0 = np.zeros(n_splits)\n",
    "    norm_L0_ELM_1 = np.zeros(n_splits)\n",
    "    norm_L0_ELM_2 = np.zeros(n_splits)\n",
    "    norm_L0_ELM_3 = np.zeros(n_splits)\n",
    "    norm_L0_ELM_4 = np.zeros(n_splits)\n",
    "    norm_L0_ELM_5 = np.zeros(n_splits)\n",
    "    \n",
    "    train_accuracy_SVM = np.zeros(n_splits)\n",
    "    test_accuracy_SVM = np.zeros(n_splits)\n",
    "    margin_SVM = np.zeros(n_splits)\n",
    "\n",
    "    margins=[]\n",
    "    margins_p1 = []\n",
    "    margins_pinf = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train = X[train_index,:]\n",
    "        X_test = X[test_index,:]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "    \n",
    "        # IM ELM\n",
    "        clf = IM_ELM(n_neurons=p, eta=eta, lambda_param=lambda_param, delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000)\n",
    "        iterations_IMA[i], updates[i], iterations_FMP[i], margin = clf.fit(X_train, y_train)\n",
    "        margins.append(margin)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_ELM[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_ELM[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_ELM[i] = accuracy_score(y_test, y_hat)\n",
    "        Z = clf.Z\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_ELM_0[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_ELM_1[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_ELM_2[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_ELM_3[i] = L0_norm(w, 0.001 * w.max())\n",
    "        norm_L0_IM_ELM_4[i] = L0_norm(w, 0.0001 * w.max())\n",
    "        norm_L0_IM_ELM_5[i] = L0_norm(w, 0.00001 * w.max())\n",
    "        \n",
    "        # ELM\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = False)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = False)\n",
    "        margin_ELM[i] = compute_margin(clf.H[:,:], y_train, clf.w_elm, 0)\n",
    "        train_accuracy_ELM[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_ELM[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w_elm\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_ELM_0[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_ELM_1[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_ELM_2[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_ELM_3[i] = L0_norm(w, 0.001 * w.max())\n",
    "        norm_L0_ELM_4[i] = L0_norm(w, 0.0001 * w.max())\n",
    "        norm_L0_ELM_5[i] = L0_norm(w, 0.00001 * w.max())\n",
    "        \n",
    "         # IM ELM p1\n",
    "        clf = IM_ELM_p1(n_neurons=p, eta=eta, lambda_param=lambda_param, delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000)\n",
    "        iterations_IMA_p1[i], updates_p1[i], iterations_FMP_p1[i], margin_p1 = clf.fit(X_train, y_train, Z)\n",
    "        margins_p1.append(margin_p1)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_ELM_p1[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_ELM_p1[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_ELM_p1[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_ELM_p1_0[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_ELM_p1_1[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_ELM_p1_2[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_ELM_p1_3[i] = L0_norm(w, 0.001 * w.max())\n",
    "        norm_L0_IM_ELM_p1_4[i] = L0_norm(w, 0.0001 * w.max())\n",
    "        norm_L0_IM_ELM_p1_5[i] = L0_norm(w, 0.00001 * w.max())\n",
    "        \n",
    "        # IM ELM p inf\n",
    "        clf = IM_ELM_pinf(n_neurons=p, eta=eta, lambda_param=lambda_param, delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000)\n",
    "        iterations_IMA_pinf[i], updates_pinf[i], iterations_FMP_pinf[i], margin_pinf = clf.fit(X_train, y_train, Z)\n",
    "        margins_pinf.append(margin_pinf)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_ELM_pinf[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_ELM_pinf[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_ELM_pinf[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_ELM_pinf_0[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_ELM_pinf_1[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_ELM_pinf_2[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_ELM_pinf_3[i] = L0_norm(w, 0.001 * w.max())\n",
    "        norm_L0_IM_ELM_pinf_4[i] = L0_norm(w, 0.0001 * w.max())\n",
    "        norm_L0_IM_ELM_pinf_5[i] = L0_norm(w, 0.00001 * w.max()) \n",
    "        i+=1\n",
    "        \n",
    "    print(\"********* Results IM ELM p=2 **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_ELM.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_ELM.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_ELM.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_ELM.std()))\n",
    "    print(\"Iterations: \" + '{:.4f}'.format(iterations_FMP.mean())+ \"+/-\" + '{:.4f}'.format(iterations_FMP.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates.mean())+ \"+/-\" + '{:.4f}'.format(updates.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_ELM.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_ELM.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_ELM_0.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_0.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_ELM_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_1.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_2.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_3.std()))\n",
    "    print(\"Norm L0 (0.01%): \" + '{:.9f}'.format(norm_L0_IM_ELM_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_4.std()))\n",
    "    print(\"Norm L0 (0.001%): \" + '{:.9f}'.format(norm_L0_IM_ELM_5.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_5.std()))\n",
    "    \n",
    "    print(\"********* Results IM ELM p=1**************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_ELM_p1.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_ELM_p1.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_ELM_p1.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_ELM_p1.std()))\n",
    "    print(\"Iterations: \" + '{:.4f}'.format(iterations_FMP_p1.mean())+ \"+/-\" + '{:.4f}'.format(iterations_FMP_p1.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA_p1.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA_p1.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates_p1.mean())+ \"+/-\" + '{:.4f}'.format(updates_p1.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_ELM_p1.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_ELM_p1.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_0.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_0.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_1.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_2.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_3.std()))\n",
    "    print(\"Norm L0 (0.01%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_4.std()))\n",
    "    print(\"Norm L0 (0.001%): \" + '{:.9f}'.format(norm_L0_IM_ELM_p1_5.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_p1_5.std()))\n",
    "    \n",
    "    print(\"********* Results IM ELM p=inf**************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_ELM_pinf.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_ELM_pinf.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_ELM_pinf.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_ELM_pinf.std()))\n",
    "    print(\"Iterations: \" + '{:.4f}'.format(iterations_FMP_pinf.mean())+ \"+/-\" + '{:.4f}'.format(iterations_FMP_pinf.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA_pinf.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA_pinf.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates_pinf.mean())+ \"+/-\" + '{:.4f}'.format(updates_pinf.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_ELM_pinf.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_ELM_pinf.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_0.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_0.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_1.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_2.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_3.std()))\n",
    "    print(\"Norm L0 (0.01%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_4.std()))\n",
    "    print(\"Norm L0 (0.001%): \" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_5.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_ELM_pinf_5.std()))\n",
    "    \n",
    "    print(\"********* Results ELM **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_ELM.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_ELM.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_ELM.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_ELM.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_ELM.mean())+ \"+/-\" + '{:.9f}'.format(margin_ELM.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_ELM_0.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_0.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_ELM_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_1.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_ELM_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_2.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_ELM_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_3.std()))\n",
    "    print(\"Norm L0 (0.01%): \" + '{:.9f}'.format(norm_L0_ELM_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_4.std()))\n",
    "    print(\"Norm L0 (0.001%): \" + '{:.9f}'.format(norm_L0_ELM_5.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_ELM_5.std()))\n",
    "    return margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Plot Margin Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_margin_evolution(m):\n",
    "    avg_margins = []\n",
    "    sem_margins = []\n",
    "    for i in range(len(m[0])):\n",
    "        margins = []\n",
    "        for j in range(len(m)):\n",
    "            margins.append(m[j][i]) \n",
    "        avg_margins.append(np.mean(margins))\n",
    "        sem_margins.append(sem(margins))\n",
    "    x = np.array(range(len(avg_margins)))\n",
    "    plt.figure(1)\n",
    "    plt.plot(x, avg_margins)\n",
    "    plt.grid()\n",
    "    plt.figure(2)\n",
    "    plt.errorbar(x, avg_margins, sem_margins, color = 'blue', marker='s', capsize=5)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGsjlM93gUvW"
   },
   "source": [
    "## Application on Iris Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRYAEinhgT0X",
    "outputId": "14dd5de2-37b1-49c2-ff7a-f8d254b84f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=150, eta=0.1, lambda=0.01\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 1598.1000+/-855.0102\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 4305.6000+/-2478.1831\n",
      "Margin: 0.669801597+/-0.051333345\n",
      "Norm L0 (20%): 94.000000000+/-6.587867637\n",
      "Norm L0 (10%): 122.400000000+/-3.903844259\n",
      "Norm L0 (1%): 146.800000000+/-1.326649916\n",
      "Norm L0 (0.1%): 149.500000000+/-0.500000000\n",
      "Norm L0 (0.01%): 149.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 150.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 774.6000+/-396.1806\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 1732.8000+/-728.8301\n",
      "Margin: 0.555064922+/-0.039272582\n",
      "Norm L0 (20%): 144.200000000+/-1.886796226\n",
      "Norm L0 (10%): 147.300000000+/-1.345362405\n",
      "Norm L0 (1%): 149.700000000+/-0.640312424\n",
      "Norm L0 (0.1%): 150.000000000+/-0.000000000\n",
      "Norm L0 (0.01%): 150.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 150.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 897.9000+/-949.6927\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 2359.4000+/-2355.8730\n",
      "Margin: 0.355211133+/-0.042670604\n",
      "Norm L0 (20%): 10.900000000+/-5.048762225\n",
      "Norm L0 (10%): 13.500000000+/-5.554277631\n",
      "Norm L0 (1%): 23.700000000+/-12.586103448\n",
      "Norm L0 (0.1%): 112.800000000+/-14.884891669\n",
      "Norm L0 (0.01%): 145.700000000+/-2.193171220\n",
      "Norm L0 (0.001%): 149.500000000+/-0.670820393\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9667+/-0.0333\n",
      "Margin: 0.000000485+/-0.000000187\n",
      "Norm L0 (20%): 52.700000000+/-15.735628364\n",
      "Norm L0 (10%): 82.400000000+/-15.717506164\n",
      "Norm L0 (1%): 140.100000000+/-4.614108798\n",
      "Norm L0 (0.1%): 149.200000000+/-0.748331477\n",
      "Norm L0 (0.01%): 150.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 150.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "# setosa - 0, versicolor - 1, virginica - 2  \n",
    "y = iris.target \n",
    "# O problema agora possui apenas as classes y=-1 e y=1\n",
    "y[y>0] = 1\n",
    "y[y==0] = -1\n",
    "m = results(X, y, 10, 150, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_F6-t8hFB_q"
   },
   "source": [
    "## Application on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Weyz8rxWFBIt",
    "outputId": "1ff193d4-c0ab-43c7-b90e-b1621657cdbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=600, eta=0.1, lambda=0.01\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9950+/-0.0107\n",
      "Iterations: 1320.0000+/-517.3517\n",
      "Iterations IMA: 19.4000+/-1.2806\n",
      "Updates: 14008.7000+/-5452.8292\n",
      "Margin: 0.432481084+/-0.020309761\n",
      "Norm L0 (20%): 253.300000000+/-49.091852685\n",
      "Norm L0 (10%): 417.200000000+/-36.138068570\n",
      "Norm L0 (1%): 580.500000000+/-4.588027899\n",
      "Norm L0 (0.1%): 597.800000000+/-1.248999600\n",
      "Norm L0 (0.01%): 600.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 600.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9950+/-0.0107\n",
      "Iterations: 478.0000+/-277.0498\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 4479.0000+/-2345.7443\n",
      "Margin: 0.335656036+/-0.019141857\n",
      "Norm L0 (20%): 532.500000000+/-15.692354826\n",
      "Norm L0 (10%): 566.900000000+/-8.080222769\n",
      "Norm L0 (1%): 595.900000000+/-2.071231518\n",
      "Norm L0 (0.1%): 600.000000000+/-0.000000000\n",
      "Norm L0 (0.01%): 600.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 600.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9967+/-0.0067\n",
      "Iterations: 439.3000+/-144.3579\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 4421.5000+/-1290.3511\n",
      "Margin: 0.312057376+/-0.016792737\n",
      "Norm L0 (20%): 76.400000000+/-18.078716769\n",
      "Norm L0 (10%): 107.500000000+/-17.517134469\n",
      "Norm L0 (1%): 184.100000000+/-30.768327871\n",
      "Norm L0 (0.1%): 520.100000000+/-20.767522722\n",
      "Norm L0 (0.01%): 591.400000000+/-4.176122604\n",
      "Norm L0 (0.001%): 598.900000000+/-1.135781669\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.7733+/-0.0624\n",
      "Margin: 0.014480311+/-0.001484165\n",
      "Norm L0 (20%): 244.100000000+/-52.947993352\n",
      "Norm L0 (10%): 399.600000000+/-38.134498817\n",
      "Norm L0 (1%): 578.700000000+/-6.372597587\n",
      "Norm L0 (0.1%): 597.600000000+/-1.200000000\n",
      "Norm L0 (0.01%): 599.800000000+/-0.600000000\n",
      "Norm L0 (0.001%): 600.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "synthetic_dataset = pd.read_csv('data/synthetic_dataset/synthetic_control.data', sep=\"\\s+\",  header=None, engine='python')\n",
    "X = synthetic_dataset.to_numpy()\n",
    "y = np.concatenate((np.ones(100), np.ones(200)*-1, np.ones(100), np.ones(100)*-1,np.ones(100)))\n",
    "m = results(X, y, 10, 600, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEyDIiTZoGap"
   },
   "source": [
    "## Application on Robot  Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUaMED7moS6p",
    "outputId": "1af62482-971b-4204-cd1e-b813d963551a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=117, eta=0.1, lambda=1.437142857142857\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.8082+/-0.0452\n",
      "Acc test: 0.8205+/-0.0690\n",
      "Iterations: 370.2000+/-85.4854\n",
      "Iterations IMA: 7.5000+/-6.5154\n",
      "Updates: 11500.6000+/-3235.4924\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 54.700000000+/-15.912573645\n",
      "Norm L0 (10%): 91.600000000+/-7.459222480\n",
      "Norm L0 (1%): 113.900000000+/-1.813835715\n",
      "Norm L0 (0.1%): 116.800000000+/-0.600000000\n",
      "Norm L0 (0.01%): 117.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 117.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.8233+/-0.0577\n",
      "Acc test: 0.8114+/-0.0745\n",
      "Iterations: 337.0000+/-85.9511\n",
      "Iterations IMA: 6.7000+/-7.0718\n",
      "Updates: 10677.2000+/-3199.6270\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 101.400000000+/-12.167168939\n",
      "Norm L0 (10%): 109.500000000+/-5.315072906\n",
      "Norm L0 (1%): 116.300000000+/-0.900000000\n",
      "Norm L0 (0.1%): 116.900000000+/-0.300000000\n",
      "Norm L0 (0.01%): 117.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 117.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.8063+/-0.0362\n",
      "Acc test: 0.7689+/-0.0570\n",
      "Iterations: 432.0000+/-179.4252\n",
      "Iterations IMA: 13.6000+/-6.6663\n",
      "Updates: 13534.7000+/-5613.1441\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 13.400000000+/-10.983624174\n",
      "Norm L0 (10%): 27.000000000+/-19.884667460\n",
      "Norm L0 (1%): 97.200000000+/-9.303762680\n",
      "Norm L0 (0.1%): 115.000000000+/-1.264911064\n",
      "Norm L0 (0.01%): 116.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 117.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.5273+/-0.2028\n",
      "Margin: 0.000141341+/-0.000073803\n",
      "Norm L0 (20%): 17.000000000+/-4.939635614\n",
      "Norm L0 (10%): 31.900000000+/-8.030566605\n",
      "Norm L0 (1%): 96.900000000+/-9.267685795\n",
      "Norm L0 (0.1%): 114.400000000+/-1.959591794\n",
      "Norm L0 (0.01%): 116.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 117.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "robot_dataset = pd.read_csv('data/robot/lp4_data.csv', delimiter =',')\n",
    "X = robot_dataset.to_numpy().reshape([117,90])\n",
    "y = np.concatenate((np.ones(24), np.ones(117-24)*-1))\n",
    "m = results(X, y, 10, 117, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=1000, eta=0.1, lambda=2.4565306122448978\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 309.9000+/-63.1798\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 6654.8000+/-2022.3394\n",
      "Margin: 1.706531914+/-0.074724859\n",
      "Norm L0 (20%): 450.800000000+/-57.606944026\n",
      "Norm L0 (10%): 696.800000000+/-35.176128269\n",
      "Norm L0 (1%): 969.100000000+/-5.262128847\n",
      "Norm L0 (0.1%): 996.800000000+/-2.088061302\n",
      "Norm L0 (0.01%): 999.700000000+/-0.458257569\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 138.1000+/-32.9983\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 1809.8000+/-736.4398\n",
      "Margin: 1.412366507+/-0.055633771\n",
      "Norm L0 (20%): 876.500000000+/-18.023595646\n",
      "Norm L0 (10%): 936.700000000+/-10.668176976\n",
      "Norm L0 (1%): 992.400000000+/-2.289104628\n",
      "Norm L0 (0.1%): 999.300000000+/-0.900000000\n",
      "Norm L0 (0.01%): 1000.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 165.3000+/-32.1685\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 3014.3000+/-981.1604\n",
      "Margin: 1.077656298+/-0.062419271\n",
      "Norm L0 (20%): 77.600000000+/-16.704490414\n",
      "Norm L0 (10%): 116.300000000+/-19.334166649\n",
      "Norm L0 (1%): 196.500000000+/-35.180250141\n",
      "Norm L0 (0.1%): 779.500000000+/-87.091044316\n",
      "Norm L0 (0.01%): 976.300000000+/-11.234322409\n",
      "Norm L0 (0.001%): 997.700000000+/-1.676305461\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Margin: 0.887007038+/-0.060240913\n",
      "Norm L0 (20%): 202.900000000+/-99.442898188\n",
      "Norm L0 (10%): 461.000000000+/-135.871998587\n",
      "Norm L0 (1%): 936.900000000+/-21.177582487\n",
      "Norm L0 (0.1%): 993.900000000+/-3.300000000\n",
      "Norm L0 (0.01%): 999.400000000+/-0.489897949\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/Mushroom/agaricus-lepiota.data', delimiter =',', header=None)\n",
    "df = df.replace(\"?\", np.nan) \n",
    "df = df.dropna() \n",
    "y = df[0].to_numpy()\n",
    "X = df.drop([0], axis='columns')\n",
    "X = pd.get_dummies(X).to_numpy()\n",
    "y[np.where(y=='e')] = -1\n",
    "y[np.where(y=='p')] = 1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 1000, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=351, eta=0.1, lambda=3.2720408163265304\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9883+/-0.0058\n",
      "Acc test: 0.9116+/-0.0606\n",
      "Iterations: 461.9000+/-54.8606\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 6004.5000+/-707.7275\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 205.500000000+/-22.983689869\n",
      "Norm L0 (10%): 277.300000000+/-15.691080269\n",
      "Norm L0 (1%): 342.200000000+/-4.237924020\n",
      "Norm L0 (0.1%): 350.100000000+/-0.943398113\n",
      "Norm L0 (0.01%): 350.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 351.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.9921+/-0.0035\n",
      "Acc test: 0.9087+/-0.0584\n",
      "Iterations: 918.3000+/-322.6931\n",
      "Iterations IMA: 18.5000+/-4.5000\n",
      "Updates: 10594.7000+/-2938.0436\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 286.700000000+/-12.594046212\n",
      "Norm L0 (10%): 319.000000000+/-8.786353055\n",
      "Norm L0 (1%): 348.000000000+/-1.732050808\n",
      "Norm L0 (0.1%): 350.700000000+/-0.458257569\n",
      "Norm L0 (0.01%): 350.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 351.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9880+/-0.0042\n",
      "Acc test: 0.9058+/-0.0689\n",
      "Iterations: 494.2000+/-58.0772\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 6200.0000+/-716.6035\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 175.500000000+/-23.165707414\n",
      "Norm L0 (10%): 245.300000000+/-17.441616898\n",
      "Norm L0 (1%): 332.500000000+/-6.020797289\n",
      "Norm L0 (0.1%): 348.800000000+/-1.469693846\n",
      "Norm L0 (0.01%): 350.700000000+/-0.640312424\n",
      "Norm L0 (0.001%): 351.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.7010+/-0.0554\n",
      "Margin: 0.002498547+/-0.000764023\n",
      "Norm L0 (20%): 166.200000000+/-27.392699757\n",
      "Norm L0 (10%): 249.700000000+/-19.360010331\n",
      "Norm L0 (1%): 338.400000000+/-3.382306905\n",
      "Norm L0 (0.1%): 350.000000000+/-1.000000000\n",
      "Norm L0 (0.01%): 350.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 351.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "ionosphere_dataset = pd.read_csv('data/Ionosphere/ionosphere.data', names=list(range(0,35)), sep=',')\n",
    "y = ionosphere_dataset[34].to_numpy()\n",
    "X = ionosphere_dataset.drop([34], axis='columns').to_numpy()\n",
    "y[np.where(y=='g')] = 1\n",
    "y[np.where(y=='b')] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 351, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Banknote Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=1000, eta=0.1, lambda=0.01\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 3777.0000+/-1312.5260\n",
      "Iterations IMA: 18.2000+/-2.7129\n",
      "Updates: 53222.0000+/-16181.3736\n",
      "Margin: 0.038050422+/-0.003727692\n",
      "Norm L0 (20%): 376.600000000+/-87.674625748\n",
      "Norm L0 (10%): 669.600000000+/-57.496434672\n",
      "Norm L0 (1%): 965.900000000+/-7.803204470\n",
      "Norm L0 (0.1%): 996.500000000+/-1.118033989\n",
      "Norm L0 (0.01%): 999.700000000+/-0.640312424\n",
      "Norm L0 (0.001%): 999.900000000+/-0.300000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.9973+/-0.0057\n",
      "Acc test: 0.9964+/-0.0059\n",
      "Iterations: 3487.5000+/-968.9105\n",
      "Iterations IMA: 14.4000+/-2.5768\n",
      "Updates: 48171.0000+/-12504.2813\n",
      "Margin: 0.008693002+/-0.009959017\n",
      "Norm L0 (20%): 846.500000000+/-20.781000938\n",
      "Norm L0 (10%): 924.100000000+/-10.511422359\n",
      "Norm L0 (1%): 992.400000000+/-3.039736831\n",
      "Norm L0 (0.1%): 999.100000000+/-1.135781669\n",
      "Norm L0 (0.01%): 999.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 1.0000+/-0.0000\n",
      "Iterations: 3403.1000+/-847.3293\n",
      "Iterations IMA: 19.6000+/-1.2000\n",
      "Updates: 49740.7000+/-11876.0586\n",
      "Margin: 0.035118550+/-0.002495845\n",
      "Norm L0 (20%): 194.500000000+/-46.748796776\n",
      "Norm L0 (10%): 359.000000000+/-51.182028096\n",
      "Norm L0 (1%): 535.900000000+/-73.157979742\n",
      "Norm L0 (0.1%): 717.700000000+/-96.993865785\n",
      "Norm L0 (0.01%): 961.200000000+/-18.454267799\n",
      "Norm L0 (0.001%): 996.400000000+/-1.685229955\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9636+/-0.0122\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 332.500000000+/-36.464366168\n",
      "Norm L0 (10%): 551.200000000+/-26.787310429\n",
      "Norm L0 (1%): 932.600000000+/-11.473447607\n",
      "Norm L0 (0.1%): 993.000000000+/-2.190890230\n",
      "Norm L0 (0.01%): 999.000000000+/-0.894427191\n",
      "Norm L0 (0.001%): 999.800000000+/-0.400000000\n"
     ]
    }
   ],
   "source": [
    "# read in banknote authentication set\n",
    "banknotes = pd.read_csv('data/banknote/data_banknote_authentication.txt', names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\n",
    "\n",
    "# convert to array\n",
    "X = banknotes[['variance', 'skewness', 'curtosis', 'entropy']].to_numpy()\n",
    "y = banknotes[['class']].to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "m = results(X, y, 10, 1000, 0.1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=178, eta=1, lambda=3.4759183673469387\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9988+/-0.0025\n",
      "Acc test: 0.9775+/-0.0276\n",
      "Iterations: 101.7000+/-14.3600\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 498.1000+/-111.4293\n",
      "Margin: 0.040775414+/-0.043580605\n",
      "Norm L0 (20%): 100.400000000+/-8.742997198\n",
      "Norm L0 (10%): 136.900000000+/-4.323193264\n",
      "Norm L0 (1%): 173.400000000+/-1.854723699\n",
      "Norm L0 (0.1%): 177.500000000+/-0.500000000\n",
      "Norm L0 (0.01%): 177.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 178.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.9830+/-0.0260\n",
      "Iterations: 113.5000+/-14.9482\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 572.0000+/-136.0529\n",
      "Margin: 0.057100118+/-0.015538195\n",
      "Norm L0 (20%): 141.300000000+/-8.258934556\n",
      "Norm L0 (10%): 159.200000000+/-4.445222154\n",
      "Norm L0 (1%): 175.600000000+/-1.685229955\n",
      "Norm L0 (0.1%): 177.600000000+/-0.489897949\n",
      "Norm L0 (0.01%): 178.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 178.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9994+/-0.0019\n",
      "Acc test: 0.9830+/-0.0260\n",
      "Iterations: 90.9000+/-7.4088\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 418.6000+/-54.0226\n",
      "Margin: 0.048188853+/-0.027594062\n",
      "Norm L0 (20%): 74.100000000+/-14.466858678\n",
      "Norm L0 (10%): 103.900000000+/-16.096272861\n",
      "Norm L0 (1%): 162.200000000+/-7.124605252\n",
      "Norm L0 (0.1%): 176.100000000+/-1.640121947\n",
      "Norm L0 (0.01%): 177.700000000+/-0.458257569\n",
      "Norm L0 (0.001%): 178.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.7807+/-0.0682\n",
      "Margin: 0.001828082+/-0.000230393\n",
      "Norm L0 (20%): 94.600000000+/-13.245376552\n",
      "Norm L0 (10%): 132.300000000+/-8.706893820\n",
      "Norm L0 (1%): 173.600000000+/-2.154065923\n",
      "Norm L0 (0.1%): 177.100000000+/-0.830662386\n",
      "Norm L0 (0.01%): 177.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 177.900000000+/-0.300000000\n"
     ]
    }
   ],
   "source": [
    "wine_dataset = pd.read_csv('data/wine/wine.data', names=['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315', 'Proline'])\n",
    "# convert to array\n",
    "y = wine_dataset[['Class']].to_numpy()\n",
    "X = wine_dataset.drop(\"Class\",axis='columns').to_numpy()\n",
    "y[np.where(y==3)] = 1\n",
    "y[np.where(y==2)] = -1\n",
    "m = results(X, y, 10, 178, 1, 20)\n",
    "#plot_margin_evolution(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on WDBC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=569, eta=0.1, lambda=4.291428571428571\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9869+/-0.0029\n",
      "Acc test: 0.9684+/-0.0131\n",
      "Iterations: 525.1000+/-44.2774\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 6672.8000+/-961.3621\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 307.600000000+/-35.327609599\n",
      "Norm L0 (10%): 435.300000000+/-22.463525992\n",
      "Norm L0 (1%): 556.800000000+/-3.370459909\n",
      "Norm L0 (0.1%): 567.600000000+/-1.200000000\n",
      "Norm L0 (0.01%): 568.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 569.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.9881+/-0.0107\n",
      "Acc test: 0.9649+/-0.0235\n",
      "Iterations: 883.4000+/-357.3780\n",
      "Iterations IMA: 4.8000+/-5.2498\n",
      "Updates: 13723.4000+/-4140.3893\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 489.400000000+/-13.828955130\n",
      "Norm L0 (10%): 529.900000000+/-7.634788799\n",
      "Norm L0 (1%): 565.200000000+/-2.039607805\n",
      "Norm L0 (0.1%): 568.200000000+/-0.979795897\n",
      "Norm L0 (0.01%): 569.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 569.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9840+/-0.0056\n",
      "Acc test: 0.9736+/-0.0162\n",
      "Iterations: 524.7000+/-58.6055\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 6959.8000+/-1122.6149\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 150.500000000+/-42.979646346\n",
      "Norm L0 (10%): 218.200000000+/-51.524363169\n",
      "Norm L0 (1%): 410.300000000+/-62.758346059\n",
      "Norm L0 (0.1%): 547.300000000+/-13.813399292\n",
      "Norm L0 (0.01%): 566.400000000+/-2.416609195\n",
      "Norm L0 (0.001%): 568.800000000+/-0.400000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.7416+/-0.0548\n",
      "Margin: 0.000486659+/-0.000042358\n",
      "Norm L0 (20%): 259.100000000+/-45.588266034\n",
      "Norm L0 (10%): 396.300000000+/-30.741014947\n",
      "Norm L0 (1%): 551.700000000+/-6.341135545\n",
      "Norm L0 (0.1%): 567.100000000+/-1.972308292\n",
      "Norm L0 (0.01%): 568.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 568.900000000+/-0.300000000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_margin_evolution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4d50121f42a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m569\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplot_margin_evolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_margin_evolution' is not defined"
     ]
    }
   ],
   "source": [
    "wdbc_dataset = pd.read_csv('data/WDBC/wdbc.data', names=list(range(0,32)))\n",
    "# convert to array\n",
    "y = wdbc_dataset[1].to_numpy()\n",
    "X = wdbc_dataset.drop([0, 1],axis='columns').to_numpy()\n",
    "y[np.where(y=='B')] = 1\n",
    "y[np.where(y=='M')] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 569, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Sonar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=208, eta=0.1, lambda=4.291428571428571\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9968+/-0.0049\n",
      "Acc test: 0.8064+/-0.0993\n",
      "Iterations: 219.8000+/-20.9370\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 3111.9000+/-336.0594\n",
      "Margin: 0.010489642+/-0.011653672\n",
      "Norm L0 (20%): 118.300000000+/-12.050311199\n",
      "Norm L0 (10%): 163.000000000+/-8.752142595\n",
      "Norm L0 (1%): 203.300000000+/-2.609597670\n",
      "Norm L0 (0.1%): 207.100000000+/-0.943398113\n",
      "Norm L0 (0.01%): 208.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 208.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.9989+/-0.0021\n",
      "Acc test: 0.8162+/-0.0935\n",
      "Iterations: 244.7000+/-28.7613\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 3459.9000+/-561.2384\n",
      "Margin: 0.018038346+/-0.013071084\n",
      "Norm L0 (20%): 156.700000000+/-9.869650450\n",
      "Norm L0 (10%): 182.700000000+/-6.634003316\n",
      "Norm L0 (1%): 205.400000000+/-1.800000000\n",
      "Norm L0 (0.1%): 207.800000000+/-0.400000000\n",
      "Norm L0 (0.01%): 207.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 207.900000000+/-0.300000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9979+/-0.0035\n",
      "Acc test: 0.7826+/-0.0843\n",
      "Iterations: 228.6000+/-27.9757\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 3159.8000+/-477.8284\n",
      "Margin: 0.012422409+/-0.011729535\n",
      "Norm L0 (20%): 105.400000000+/-15.167069592\n",
      "Norm L0 (10%): 144.400000000+/-11.473447607\n",
      "Norm L0 (1%): 197.000000000+/-3.949683532\n",
      "Norm L0 (0.1%): 207.000000000+/-0.632455532\n",
      "Norm L0 (0.01%): 208.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 208.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.7105+/-0.1292\n",
      "Margin: 0.020768938+/-0.004707855\n",
      "Norm L0 (20%): 113.700000000+/-14.014635208\n",
      "Norm L0 (10%): 159.000000000+/-8.197560613\n",
      "Norm L0 (1%): 202.300000000+/-2.758622845\n",
      "Norm L0 (0.1%): 207.200000000+/-1.248999600\n",
      "Norm L0 (0.01%): 207.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 208.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "sonar_dataset = pd.read_csv('data/sonar/sonar.all-data', names=list(range(0,61)), sep=',')\n",
    "y = sonar_dataset[60].to_numpy()\n",
    "X = sonar_dataset.drop([60], axis='columns').to_numpy()\n",
    "y[np.where(y=='R')] = 1\n",
    "y[np.where(y=='M')] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 208, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Pima Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=768, eta=0.1, lambda=6.534081632653061\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.7835+/-0.0100\n",
      "Acc test: 0.7370+/-0.0251\n",
      "Iterations: 401.4000+/-23.7874\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 43226.2000+/-1518.9328\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 234.600000000+/-45.596491093\n",
      "Norm L0 (10%): 440.800000000+/-43.641264876\n",
      "Norm L0 (1%): 736.400000000+/-4.409081537\n",
      "Norm L0 (0.1%): 764.200000000+/-1.469693846\n",
      "Norm L0 (0.01%): 767.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 768.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.7217+/-0.0481\n",
      "Acc test: 0.7162+/-0.0416\n",
      "Iterations: 72.8000+/-19.4463\n",
      "Iterations IMA: 2.2000+/-0.4000\n",
      "Updates: 12790.8000+/-1039.2100\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 556.800000000+/-97.532353606\n",
      "Norm L0 (10%): 659.200000000+/-52.632309469\n",
      "Norm L0 (1%): 756.200000000+/-4.955804677\n",
      "Norm L0 (0.1%): 767.600000000+/-0.489897949\n",
      "Norm L0 (0.01%): 767.800000000+/-0.400000000\n",
      "Norm L0 (0.001%): 768.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.7858+/-0.0077\n",
      "Acc test: 0.7513+/-0.0286\n",
      "Iterations: 400.8000+/-13.8910\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 42261.8000+/-1395.2444\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 138.600000000+/-35.651647928\n",
      "Norm L0 (10%): 251.800000000+/-38.300913827\n",
      "Norm L0 (1%): 612.000000000+/-34.380226875\n",
      "Norm L0 (0.1%): 750.000000000+/-6.752777206\n",
      "Norm L0 (0.01%): 767.200000000+/-0.748331477\n",
      "Norm L0 (0.001%): 768.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.5587+/-0.0488\n",
      "Margin: 0.000000833+/-0.000000076\n",
      "Norm L0 (20%): 323.000000000+/-24.899799196\n",
      "Norm L0 (10%): 518.600000000+/-20.185143051\n",
      "Norm L0 (1%): 741.400000000+/-2.497999199\n",
      "Norm L0 (0.1%): 766.200000000+/-0.979795897\n",
      "Norm L0 (0.01%): 768.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 768.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "pima_dataset = pd.read_csv('data/diabetes/diabetes.csv', sep=\",\", engine='python')\n",
    "y = pima_dataset['Outcome'].to_numpy()\n",
    "X = pima_dataset.drop(['Outcome'], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 5, 768, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Statlog Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=270, eta=0.1, lambda=7.553469387755102\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.8757+/-0.0249\n",
      "Acc test: 0.7963+/-0.0727\n",
      "Iterations: 299.1000+/-39.2822\n",
      "Iterations IMA: 18.2000+/-5.4000\n",
      "Updates: 7822.1000+/-1025.3015\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 130.400000000+/-16.378034070\n",
      "Norm L0 (10%): 196.100000000+/-8.734414691\n",
      "Norm L0 (1%): 260.800000000+/-2.785677655\n",
      "Norm L0 (0.1%): 269.400000000+/-0.663324958\n",
      "Norm L0 (0.01%): 270.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 270.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.8510+/-0.0453\n",
      "Acc test: 0.7778+/-0.0597\n",
      "Iterations: 223.4000+/-27.1522\n",
      "Iterations IMA: 2.0000+/-0.0000\n",
      "Updates: 10461.8000+/-47.3324\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 226.400000000+/-8.309031231\n",
      "Norm L0 (10%): 249.800000000+/-5.230678732\n",
      "Norm L0 (1%): 268.700000000+/-1.100000000\n",
      "Norm L0 (0.1%): 269.900000000+/-0.300000000\n",
      "Norm L0 (0.01%): 270.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 270.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.8786+/-0.0171\n",
      "Acc test: 0.7852+/-0.0825\n",
      "Iterations: 310.5000+/-14.1510\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 7539.1000+/-390.8315\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 76.700000000+/-12.961867149\n",
      "Norm L0 (10%): 122.200000000+/-13.854963010\n",
      "Norm L0 (1%): 235.900000000+/-12.809761903\n",
      "Norm L0 (0.1%): 265.900000000+/-2.426932220\n",
      "Norm L0 (0.01%): 269.200000000+/-0.748331477\n",
      "Norm L0 (0.001%): 269.900000000+/-0.300000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.5889+/-0.0785\n",
      "Margin: 0.001355842+/-0.000368161\n",
      "Norm L0 (20%): 128.100000000+/-11.246777316\n",
      "Norm L0 (10%): 194.500000000+/-8.127115109\n",
      "Norm L0 (1%): 262.100000000+/-2.467792536\n",
      "Norm L0 (0.1%): 269.500000000+/-0.670820393\n",
      "Norm L0 (0.01%): 269.800000000+/-0.600000000\n",
      "Norm L0 (0.001%): 270.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "statlog_dataset = pd.read_csv('data/statlog/heart.dat', sep=\" \", header=None, engine='python')\n",
    "y = statlog_dataset[13].to_numpy()\n",
    "X = statlog_dataset.drop([13], axis='columns').to_numpy()\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 270, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Mammographic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=830, eta=0.1, lambda=6.1263265306122445\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.8320+/-0.0045\n",
      "Acc test: 0.8325+/-0.0518\n",
      "Iterations: 521.7000+/-20.6787\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 52971.2000+/-1485.7010\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 496.100000000+/-36.231064020\n",
      "Norm L0 (10%): 661.900000000+/-20.334453521\n",
      "Norm L0 (1%): 812.600000000+/-5.407402334\n",
      "Norm L0 (0.1%): 828.400000000+/-1.113552873\n",
      "Norm L0 (0.01%): 829.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 830.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.8118+/-0.0177\n",
      "Acc test: 0.8048+/-0.0567\n",
      "Iterations: 81.4000+/-19.2676\n",
      "Iterations IMA: 2.1000+/-0.3000\n",
      "Updates: 13209.6000+/-1256.6015\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 660.200000000+/-27.942082957\n",
      "Norm L0 (10%): 744.200000000+/-17.348198754\n",
      "Norm L0 (1%): 821.000000000+/-3.033150178\n",
      "Norm L0 (0.1%): 828.900000000+/-1.044030651\n",
      "Norm L0 (0.01%): 829.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 830.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.8293+/-0.0056\n",
      "Acc test: 0.8229+/-0.0457\n",
      "Iterations: 524.1000+/-21.8607\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 52423.8000+/-2089.2040\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 375.100000000+/-49.613405447\n",
      "Norm L0 (10%): 510.300000000+/-48.503711198\n",
      "Norm L0 (1%): 719.100000000+/-30.615192307\n",
      "Norm L0 (0.1%): 819.500000000+/-3.853569774\n",
      "Norm L0 (0.01%): 828.400000000+/-0.916515139\n",
      "Norm L0 (0.001%): 830.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 0.9070+/-0.0048\n",
      "Acc test: 0.7325+/-0.0493\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 267.400000000+/-38.252320191\n",
      "Norm L0 (10%): 492.900000000+/-34.832312585\n",
      "Norm L0 (1%): 792.200000000+/-6.144916598\n",
      "Norm L0 (0.1%): 827.000000000+/-2.000000000\n",
      "Norm L0 (0.01%): 829.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 829.900000000+/-0.300000000\n"
     ]
    }
   ],
   "source": [
    "mammo = pd.read_csv('data/mammographic/mammographic_masses.data', sep=\",\", header=None, engine='python')\n",
    "mammo = mammo.replace(\"?\", np.nan)\n",
    "mammo = mammo.dropna()\n",
    "y = mammo[5].to_numpy()\n",
    "X = mammo.drop([5], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 830, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Haberman Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=306, eta=0.1, lambda=4.6991836734693875\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.7360+/-0.0061\n",
      "Acc test: 0.7451+/-0.0283\n",
      "Iterations: 125.3000+/-35.8638\n",
      "Iterations IMA: 2.4000+/-0.9165\n",
      "Updates: 10894.7000+/-604.5360\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 152.900000000+/-29.857829794\n",
      "Norm L0 (10%): 225.600000000+/-23.555041923\n",
      "Norm L0 (1%): 297.600000000+/-3.168595904\n",
      "Norm L0 (0.1%): 304.700000000+/-1.004987562\n",
      "Norm L0 (0.01%): 305.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 306.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.7364+/-0.0155\n",
      "Acc test: 0.7219+/-0.0491\n",
      "Iterations: 111.5000+/-17.7158\n",
      "Iterations IMA: 2.0000+/-0.0000\n",
      "Updates: 10621.6000+/-101.6614\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 230.300000000+/-18.809837852\n",
      "Norm L0 (10%): 265.900000000+/-13.714590770\n",
      "Norm L0 (1%): 302.400000000+/-2.059126028\n",
      "Norm L0 (0.1%): 305.900000000+/-0.300000000\n",
      "Norm L0 (0.01%): 305.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 306.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.7353+/-0.0011\n",
      "Acc test: 0.7353+/-0.0094\n",
      "Iterations: 307.8000+/-122.8265\n",
      "Iterations IMA: 9.3000+/-3.2265\n",
      "Updates: 16307.7000+/-3077.4727\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 154.400000000+/-25.892856158\n",
      "Norm L0 (10%): 224.000000000+/-17.905306476\n",
      "Norm L0 (1%): 297.700000000+/-3.436568055\n",
      "Norm L0 (0.1%): 305.700000000+/-0.458257569\n",
      "Norm L0 (0.01%): 306.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 306.000000000+/-0.000000000\n",
      "********* Results ELM **************\n",
      "Acc train: 0.9684+/-0.0033\n",
      "Acc test: 0.6632+/-0.0756\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 128.500000000+/-18.260613352\n",
      "Norm L0 (10%): 195.200000000+/-15.387007506\n",
      "Norm L0 (1%): 293.300000000+/-5.216320542\n",
      "Norm L0 (0.1%): 304.900000000+/-1.135781669\n",
      "Norm L0 (0.01%): 306.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 306.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "haberman = pd.read_csv('data/haberman/haberman.data', sep=\",\", header=None, engine='python')\n",
    "y = haberman[3].to_numpy()\n",
    "X = haberman.drop([3], axis='columns').to_numpy()\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 306, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Transfusion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=748, eta=0.1, lambda=1.8448979591836736\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.7736+/-0.0038\n",
      "Acc test: 0.7701+/-0.0224\n",
      "Iterations: 87.1000+/-59.8923\n",
      "Iterations IMA: 2.5000+/-1.2042\n",
      "Updates: 16705.3000+/-8488.3769\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 197.400000000+/-48.371892665\n",
      "Norm L0 (10%): 403.900000000+/-51.227824471\n",
      "Norm L0 (1%): 710.300000000+/-6.870953355\n",
      "Norm L0 (0.1%): 743.900000000+/-2.507987241\n",
      "Norm L0 (0.01%): 747.400000000+/-0.916515139\n",
      "Norm L0 (0.001%): 748.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.7760+/-0.0087\n",
      "Acc test: 0.7782+/-0.0336\n",
      "Iterations: 62.0000+/-7.7717\n",
      "Iterations IMA: 2.0000+/-0.0000\n",
      "Updates: 13302.6000+/-854.5036\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 605.800000000+/-35.346286934\n",
      "Norm L0 (10%): 675.600000000+/-20.824024587\n",
      "Norm L0 (1%): 738.600000000+/-2.576819745\n",
      "Norm L0 (0.1%): 747.000000000+/-1.000000000\n",
      "Norm L0 (0.01%): 747.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 748.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.7663+/-0.0022\n",
      "Acc test: 0.7661+/-0.0101\n",
      "Iterations: 257.2000+/-165.6574\n",
      "Iterations IMA: 5.2000+/-2.2716\n",
      "Updates: 31340.7000+/-14005.8854\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 84.900000000+/-134.918827448\n",
      "Norm L0 (10%): 135.200000000+/-205.010633871\n",
      "Norm L0 (1%): 500.200000000+/-168.786729336\n",
      "Norm L0 (0.1%): 718.900000000+/-21.290608258\n",
      "Norm L0 (0.01%): 745.000000000+/-2.449489743\n",
      "Norm L0 (0.001%): 747.800000000+/-0.400000000\n",
      "********* Results ELM **************\n",
      "Acc train: 0.8691+/-0.0048\n",
      "Acc test: 0.6963+/-0.0604\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 252.700000000+/-42.145106478\n",
      "Norm L0 (10%): 443.800000000+/-32.923547804\n",
      "Norm L0 (1%): 715.200000000+/-7.691553809\n",
      "Norm L0 (0.1%): 745.600000000+/-1.685229955\n",
      "Norm L0 (0.01%): 747.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 748.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "transfusion = pd.read_csv('data/transfusion/transfusion.data', sep=\",\", engine='python')\n",
    "y = transfusion[\"whether he/she donated blood in March 2007\"].to_numpy()\n",
    "X = transfusion.drop([\"whether he/she donated blood in March 2007\"], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 748, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Australian Credit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=1000, eta=0.1, lambda=8.572857142857142\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9047+/-0.0038\n",
      "Acc test: 0.8609+/-0.0269\n",
      "Iterations: 657.3000+/-25.2430\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 38250.3000+/-1765.9727\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 433.300000000+/-50.517422737\n",
      "Norm L0 (10%): 692.300000000+/-30.070084802\n",
      "Norm L0 (1%): 968.600000000+/-7.952358141\n",
      "Norm L0 (0.1%): 997.200000000+/-1.536229150\n",
      "Norm L0 (0.01%): 999.700000000+/-0.458257569\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.8786+/-0.0114\n",
      "Acc test: 0.8652+/-0.0337\n",
      "Iterations: 151.0000+/-41.1971\n",
      "Iterations IMA: 2.1000+/-0.3000\n",
      "Updates: 13089.3000+/-2274.6447\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 675.000000000+/-61.736536994\n",
      "Norm L0 (10%): 831.700000000+/-30.620418025\n",
      "Norm L0 (1%): 984.200000000+/-4.069397990\n",
      "Norm L0 (0.1%): 998.500000000+/-1.431782106\n",
      "Norm L0 (0.01%): 999.900000000+/-0.300000000\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9045+/-0.0072\n",
      "Acc test: 0.8536+/-0.0246\n",
      "Iterations: 650.1000+/-25.3947\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 37828.8000+/-1892.4502\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 352.400000000+/-38.851512197\n",
      "Norm L0 (10%): 580.900000000+/-33.431871022\n",
      "Norm L0 (1%): 918.200000000+/-18.529975715\n",
      "Norm L0 (0.1%): 991.600000000+/-3.006659276\n",
      "Norm L0 (0.01%): 999.500000000+/-0.670820393\n",
      "Norm L0 (0.001%): 999.800000000+/-0.400000000\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.4768+/-0.0717\n",
      "Margin: 0.000025978+/-0.000014173\n",
      "Norm L0 (20%): 461.800000000+/-56.343233844\n",
      "Norm L0 (10%): 714.600000000+/-41.250939383\n",
      "Norm L0 (1%): 970.400000000+/-7.901898506\n",
      "Norm L0 (0.1%): 997.400000000+/-2.009975124\n",
      "Norm L0 (0.01%): 999.600000000+/-0.663324958\n",
      "Norm L0 (0.001%): 999.900000000+/-0.300000000\n"
     ]
    }
   ],
   "source": [
    "australian = pd.read_csv('data/australian_credit/australian.dat', header=None, sep=\" \", engine='python')\n",
    "australian = australian.replace(\"?\", np.nan)\n",
    "australian = australian.dropna()\n",
    "y = australian[14].to_numpy()\n",
    "X = australian.drop([14], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 1000, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=683, eta=0.1, lambda=3.2720408163265304\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.9710+/-0.0061\n",
      "Acc test: 0.9678+/-0.0245\n",
      "Iterations: 468.2000+/-106.3765\n",
      "Iterations IMA: 6.1000+/-7.0064\n",
      "Updates: 11067.1000+/-1159.5944\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 262.900000000+/-79.300000000\n",
      "Norm L0 (10%): 438.000000000+/-66.816165709\n",
      "Norm L0 (1%): 659.000000000+/-8.136338243\n",
      "Norm L0 (0.1%): 680.300000000+/-1.552417470\n",
      "Norm L0 (0.01%): 682.600000000+/-0.489897949\n",
      "Norm L0 (0.001%): 683.000000000+/-0.000000000\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.9758+/-0.0050\n",
      "Acc test: 0.9736+/-0.0172\n",
      "Iterations: 353.3000+/-35.3470\n",
      "Iterations IMA: 2.0000+/-0.0000\n",
      "Updates: 10504.5000+/-34.7570\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 591.400000000+/-28.316779478\n",
      "Norm L0 (10%): 638.900000000+/-16.603915201\n",
      "Norm L0 (1%): 679.300000000+/-2.609597670\n",
      "Norm L0 (0.1%): 682.700000000+/-0.458257569\n",
      "Norm L0 (0.01%): 683.000000000+/-0.000000000\n",
      "Norm L0 (0.001%): 683.000000000+/-0.000000000\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.9735+/-0.0025\n",
      "Acc test: 0.9707+/-0.0174\n",
      "Iterations: 513.6000+/-19.1374\n",
      "Iterations IMA: 20.0000+/-0.0000\n",
      "Updates: 9815.2000+/-547.4694\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 48.600000000+/-18.650469163\n",
      "Norm L0 (10%): 82.600000000+/-31.777979797\n",
      "Norm L0 (1%): 356.500000000+/-123.483804606\n",
      "Norm L0 (0.1%): 639.500000000+/-22.019309708\n",
      "Norm L0 (0.01%): 678.400000000+/-3.200000000\n",
      "Norm L0 (0.001%): 682.400000000+/-0.916515139\n",
      "********* Results ELM **************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.8490+/-0.0450\n",
      "Margin: 0.000438047+/-0.000035402\n",
      "Norm L0 (20%): 332.900000000+/-33.765218791\n",
      "Norm L0 (10%): 493.500000000+/-24.630265934\n",
      "Norm L0 (1%): 660.700000000+/-5.292447449\n",
      "Norm L0 (0.1%): 680.300000000+/-1.615549442\n",
      "Norm L0 (0.01%): 682.600000000+/-0.663324958\n",
      "Norm L0 (0.001%): 683.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "breast = pd.read_csv('data/breast/breast.data', header=None, sep=\",\", engine='python')\n",
    "breast = breast.replace(\"?\", np.nan)\n",
    "breast = breast.dropna()\n",
    "y = breast[10].to_numpy()\n",
    "X = breast.drop([0, 10], axis='columns').to_numpy()\n",
    "y[np.where(y==4)] = 1\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 683, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on Spam Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: p=1000, eta=0.1, lambda=3.679795918367347\n",
      "********* Results IM ELM p=2 **************\n",
      "Acc train: 0.7029+/-0.1481\n",
      "Acc test: 0.7033+/-0.1487\n",
      "Iterations: 247.5000+/-284.7178\n",
      "Iterations IMA: 6.7000+/-8.7069\n",
      "Updates: 53323.8000+/-66209.7456\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 131.200000000+/-201.557832892\n",
      "Norm L0 (10%): 206.600000000+/-315.751547898\n",
      "Norm L0 (1%): 290.800000000+/-444.205763132\n",
      "Norm L0 (0.1%): 299.100000000+/-456.883015662\n",
      "Norm L0 (0.01%): 300.000000000+/-458.257569496\n",
      "Norm L0 (0.001%): 300.000000000+/-458.257569496\n",
      "********* Results IM ELM p=1**************\n",
      "Acc train: 0.6897+/-0.1287\n",
      "Acc test: 0.6879+/-0.1260\n",
      "Iterations: 69.8000+/-13.8477\n",
      "Iterations IMA: 1.3000+/-0.4583\n",
      "Updates: 13041.1000+/-4557.3034\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 182.200000000+/-279.763757481\n",
      "Norm L0 (10%): 240.500000000+/-367.762219376\n",
      "Norm L0 (1%): 293.700000000+/-448.635052130\n",
      "Norm L0 (0.1%): 299.300000000+/-457.188374743\n",
      "Norm L0 (0.01%): 300.000000000+/-458.257569496\n",
      "Norm L0 (0.001%): 300.000000000+/-458.257569496\n",
      "********* Results IM ELM p=inf**************\n",
      "Acc train: 0.7019+/-0.1466\n",
      "Acc test: 0.7010+/-0.1451\n",
      "Iterations: 253.4000+/-293.5358\n",
      "Iterations IMA: 6.7000+/-8.7069\n",
      "Updates: 53464.0000+/-66333.4867\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 125.100000000+/-192.489194502\n",
      "Norm L0 (10%): 198.500000000+/-303.561937667\n",
      "Norm L0 (1%): 287.200000000+/-438.708513708\n",
      "Norm L0 (0.1%): 299.000000000+/-456.731211984\n",
      "Norm L0 (0.01%): 300.000000000+/-458.257569496\n",
      "Norm L0 (0.001%): 300.000000000+/-458.257569496\n",
      "********* Results ELM **************\n",
      "Acc train: 0.9598+/-0.0008\n",
      "Acc test: 0.9113+/-0.0125\n",
      "Margin: 0.000000000+/-0.000000000\n",
      "Norm L0 (20%): 347.800000000+/-57.525298782\n",
      "Norm L0 (10%): 623.300000000+/-52.653679833\n",
      "Norm L0 (1%): 960.100000000+/-9.224424101\n",
      "Norm L0 (0.1%): 995.900000000+/-2.662705391\n",
      "Norm L0 (0.01%): 999.300000000+/-1.004987562\n",
      "Norm L0 (0.001%): 1000.000000000+/-0.000000000\n"
     ]
    }
   ],
   "source": [
    "spam = pd.read_csv('data/spam/spambase.data', header=None, sep=\",\", engine='python')\n",
    "y = spam[57].to_numpy()\n",
    "X = spam.drop([57], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "m = results(X, y, 10, 1000, 0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.557438524302"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [2, 2, 3, 5, 1]\n",
    "LA.norm(w, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "Large_Margin_Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
