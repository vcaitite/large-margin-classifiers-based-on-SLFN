{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_digits\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from copy import deepcopy\n",
    "from sklearn.cluster import KMeans\n",
    "from numba import jit, cuda\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "file_path = 'output.txt'\n",
    "sys.stdout = open(file_path, \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L0_norm(w, threshold):\n",
    "    l0_norm = 0\n",
    "    for wi in w:\n",
    "        if abs(wi) > threshold:\n",
    "            l0_norm += 1\n",
    "    return l0_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_margin(X, y, w, b):\n",
    "    margin = []\n",
    "    for i in range(y.shape[0]):\n",
    "        margin.append((y[i]*(np.dot(X[i,:], w)+b))/sqrt(sum(w**2))) \n",
    "    if min(margin) >= 0:\n",
    "        return min(margin)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class RBF_IMA(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    # Inicialization of important parameters \n",
    "    def __init__(self, n_neurons, eta=0.1, lambda_param=0.01, delta_margin=10^-3,\n",
    "                 IMA_iterations=20, max_updates=10000, p='2'):\n",
    "        self.n_neurons = n_neurons              # Neurons of hidden layer osf RBF\n",
    "        self.eta = eta                          # Learning rate\n",
    "        self.lambda_param = lambda_param        # Param important of soft margin\n",
    "        self.delta_margin = delta_margin        # (1 + delta_margin) * fixed margin defines the minimum next margin of IMA\n",
    "        self.IMA_iterations = IMA_iterations    # Maximum number of iterations of IMA\n",
    "        self.max_updates = max_updates          # Maximum number of updates in one execution of FMP\n",
    "        self.w = np.array([])                   # Vector of weights of the last layer of the RBF obtained after the training of the IMA\n",
    "        self.w_rbf = np.array([])               # Vector of weights of the last layer of the RBF obtained after the normal training of RBF\n",
    "        self.H = np.array([])                   # H matrix of RBF (obtained with training data)\n",
    "        self.Z = np.array([])                   # Z matrix of RBF\n",
    "        self.b = 0\n",
    "        self.p = p \n",
    "        self.centers = []\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(target_backend='cuda')    \n",
    "    def pdfnvar(pairwise_dist, sigma):\n",
    "        return np.exp(-pairwise_dist ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "    # Fixed Margin Algorithm\n",
    "    @staticmethod\n",
    "    @jit(target_backend='cuda')    \n",
    "    def FMP_algorithm(X, y, w_init, b_init, fixed_margin, idx, s, lambda_param, eta, max_updates, p):\n",
    "        t = 0\n",
    "        iterations = 0\n",
    "        w = w_init\n",
    "        b = b_init\n",
    "        if p == 'inf':\n",
    "            norm_w = LA.norm(w, ord=1)\n",
    "        elif p == '1':\n",
    "            norm_w = LA.norm(w, ord=np.inf)\n",
    "        else: # p == 2\n",
    "            norm_w = sqrt(sum(w**2))\n",
    "        \n",
    "        last_t = -1\n",
    "        lambda_t = 0\n",
    "        alpha = np.zeros((X.shape[0]))\n",
    "        while True:\n",
    "            last_t = t\n",
    "            e=0\n",
    "            for k in range(0, y.shape[0]):\n",
    "                i = int(idx[k])\n",
    "                if(y[i]*(np.dot(X[i,:], w)+b) <= fixed_margin * norm_w - lambda_param * alpha[i]):\n",
    "                    if norm_w != 0:\n",
    "                        lambda_t = 1 - (eta*fixed_margin)/norm_w\n",
    "                    else:\n",
    "                        lambda_t = 1\n",
    "                    alpha = alpha * lambda_t\n",
    "                    alpha[i] = alpha[i] + eta  \n",
    "                    if p == 'inf':\n",
    "                        w = w - eta * (fixed_margin * np.sign(w) - y[i] * X[i,:])\n",
    "                        norm_w = LA.norm(w, ord=1)\n",
    "                    elif p == '1':\n",
    "                        for j in range(len(w)):\n",
    "                            if abs(w[j]) == norm_w:\n",
    "                                w[j] = w[j] - eta * (fixed_margin * np.sign(w[j])/sum(np.abs(w) == norm_w) - y[i] * X[i,j])\n",
    "                            elif abs(w[j]) < norm_w:\n",
    "                                w[j] = w[j] + eta * (y[i] * X[i,j])\n",
    "                        norm_w = LA.norm(w, ord=np.inf)\n",
    "                    else: # p == 2\n",
    "                        w = w * lambda_t + eta * y[i] * X[i,:]\n",
    "                        norm_w = sqrt(sum(w**2))\n",
    "                    b = b + eta*y[i]\n",
    "                    t += 1\n",
    "                    e += 1\n",
    "                    if k > s:\n",
    "                        s += 1\n",
    "                        j = s\n",
    "                    else:\n",
    "                        j=e\n",
    "                    idx[k], idx[j] = idx[j], idx[k]\n",
    "            iterations += 1\n",
    "            if (t > max_updates or last_t == t):\n",
    "                break\n",
    "        if t<= max_updates:\n",
    "            convergence=1\n",
    "        else:\n",
    "            convergence=0\n",
    "        return w, b, convergence, t, iterations, idx, s\n",
    "\n",
    "    # IMA Algorithm\n",
    "    def IM_algorithm(self, X, y):\n",
    "        self.w = np.ones(self.w_rbf.shape[0]) * 0.000001\n",
    "        self.ws = [] \n",
    "        self.bs = [] \n",
    "        self.ws.append(self.w)\n",
    "        self.bs.append(self.b)\n",
    "        fixed_margin = 0#compute_margin(X, y, self.w_RBF, self.b)\n",
    "        t = 0\n",
    "        convergence = 1\n",
    "        updates=0\n",
    "        iterations=0\n",
    "        margin=[]\n",
    "        margin.append(fixed_margin)\n",
    "        idx = np.linspace(0, y.shape[0]-1, y.shape[0])\n",
    "        s=0\n",
    "        while convergence==1 and t<self.IMA_iterations:\n",
    "            w, b, convergence, updates_, iterations_, idx, s = self.FMP_algorithm(X, y, self.w, self.b, fixed_margin, idx, s, self.lambda_param, self.eta, self.max_updates, self.p)\n",
    "            if convergence == 1:\n",
    "                self.w = w\n",
    "                self.b = b\n",
    "                self.ws.append(self.w)\n",
    "                self.bs.append(self.b)\n",
    "            updates += updates_\n",
    "            iterations += iterations_\n",
    "            \n",
    "            if self.p == 'inf':\n",
    "                norm_w = LA.norm(w, ord=1)\n",
    "            elif self.p == '1':\n",
    "                norm_w = LA.norm(w, ord=np.inf)\n",
    "            else: # p == 2\n",
    "                norm_w = sqrt(sum(w**2))\n",
    "            \n",
    "            gamma1 = []\n",
    "            gamma2 = []\n",
    "            for i in range(0, y.shape[0]):\n",
    "                if y[i] == 1:\n",
    "                    gamma1.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "                else:\n",
    "                    gamma2.append((y[i]*(np.dot(X[i], self.w)+self.b))/norm_w)\n",
    "            gamma1 = np.array(gamma1)\n",
    "            gamma2 = np.array(gamma2)\n",
    "            gamma1 = gamma1[gamma1>=0]\n",
    "            gamma2 = gamma2[gamma2>=0]\n",
    "            if len(gamma1) == 0:\n",
    "                min_gamma1 = 0\n",
    "            else:\n",
    "                min_gamma1 = min(gamma1)\n",
    "            if len(gamma2) == 0:\n",
    "                min_gamma2 = 0\n",
    "            else:\n",
    "                min_gamma2 = min(gamma2)\n",
    "            fixed_margin = max([(min_gamma1 + min_gamma2)/2, (1+self.delta_margin)*fixed_margin])\n",
    "            #margin.append(compute_margin(X, y, self.w, self.b))\n",
    "            t += 1\n",
    "        return t, updates, iterations, margin\n",
    "\n",
    "    # Function that manage the training of IMA RBF\n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0] # number of samples\n",
    "        n = X.shape[1] # samples dimension\n",
    "        \n",
    "        if self.centers == []:\n",
    "            # Applying K-mean to separate the clusters:\n",
    "            kmeans = KMeans(n_clusters=self.n_neurons).fit(X)\n",
    "            # Capture the centers:\n",
    "            self.centers = kmeans.cluster_centers_\n",
    "\n",
    "        pairwise_dist = pairwise_distances(X, self.centers)\n",
    "\n",
    "        self.sigma = np.mean(np.mean(pairwise_dist, axis=1))\n",
    "        \n",
    "        self.H = self.pdfnvar(pairwise_dist, self.sigma)\n",
    "\n",
    "        #self.H = np.hstack((self.H, np.ones((self.H.shape[0], 1))))\n",
    "\n",
    "        self.w_rbf = np.dot(np.linalg.pinv(self.H), y)\n",
    "        \n",
    "        iterations_IMA, updates, iterations, margin = self.IM_algorithm(self.H, y) \n",
    "        \n",
    "        return iterations_IMA, updates, iterations, margin\n",
    "            \n",
    "    # Function to apply IMA RBF model\n",
    "    def predict(self, X, use_IMA_w=True):\n",
    "        pairwise_dist = pairwise_distances(X, self.centers)\n",
    "        H = self.pdfnvar(pairwise_dist, self.sigma)\n",
    "        #H = np.hstack((H, np.ones((H.shape[0], 1))))\n",
    "        if use_IMA_w == True:\n",
    "            y_predicted = np.sign(np.dot(H, self.w) + self.b)\n",
    "        else:\n",
    "            y_predicted = np.sign(np.dot(H,  self.w_rbf))\n",
    "        y_predicted[y_predicted==0]=-1\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(X, y, n_splits, p, eta, IMA_iterations, lambda_param):    \n",
    "      \n",
    "    print(f'Parameters: p={p}, eta={eta}, lambda={lambda_param}')\n",
    "\n",
    "    # Stratified k fold cross validation\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=72)\n",
    "    i=0\n",
    "    \n",
    "    train_accuracy_IM_RBF_p2 = np.zeros(n_splits)\n",
    "    test_accuracy_IM_RBF_p2 = np.zeros(n_splits)\n",
    "    margin_IM_RBF_p2 = np.zeros(n_splits)\n",
    "    updates_p2 = np.zeros(n_splits)\n",
    "    iterations_IMA_p2 = np.zeros(n_splits)\n",
    "    iterations_FMP_p2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p2_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p2_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p2_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p2_4 = np.zeros(n_splits)\n",
    "          \n",
    "    train_accuracy_IM_RBF_p1 = np.zeros(n_splits)\n",
    "    test_accuracy_IM_RBF_p1 = np.zeros(n_splits)\n",
    "    margin_IM_RBF_p1 = np.zeros(n_splits)\n",
    "    updates_p1 = np.zeros(n_splits)\n",
    "    iterations_IMA_p1 = np.zeros(n_splits)\n",
    "    iterations_FMP_p1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p1_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p1_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p1_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_p1_4 = np.zeros(n_splits)\n",
    "\n",
    "    train_accuracy_IM_RBF_pinf = np.zeros(n_splits)\n",
    "    test_accuracy_IM_RBF_pinf = np.zeros(n_splits)\n",
    "    margin_IM_RBF_pinf = np.zeros(n_splits)\n",
    "    updates_pinf = np.zeros(n_splits)\n",
    "    iterations_IMA_pinf = np.zeros(n_splits)\n",
    "    iterations_FMP_pinf = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_pinf_1 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_pinf_2 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_pinf_3 = np.zeros(n_splits)\n",
    "    norm_L0_IM_RBF_pinf_4 = np.zeros(n_splits)\n",
    "\n",
    "    train_accuracy_RBF = np.zeros(n_splits)\n",
    "    test_accuracy_RBF = np.zeros(n_splits)\n",
    "    margin_RBF = np.zeros(n_splits)\n",
    "    norm_L0_RBF_1 = np.zeros(n_splits)\n",
    "    norm_L0_RBF_2 = np.zeros(n_splits)\n",
    "    norm_L0_RBF_3 = np.zeros(n_splits)\n",
    "    norm_L0_RBF_4 = np.zeros(n_splits)\n",
    "\n",
    "    margins=[]\n",
    "        \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train = X[train_index,:]\n",
    "        X_test = X[test_index,:]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "               \n",
    "        # RBF-IMA 2\n",
    "        clf = RBF_IMA(n_neurons=p, eta=eta, lambda_param=lambda_param[1], delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000, p='2')\n",
    "        iterations_IMA_p2[i], updates_p2[i], iterations_FMP_p2[i], margin = clf.fit(X_train, y_train)\n",
    "        centers = clf.centers\n",
    "        margins.append(margin)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_RBF_p2[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_RBF_p2[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_RBF_p2[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_RBF_p2_1[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_RBF_p2_2[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_RBF_p2_3[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_RBF_p2_4[i] = L0_norm(w, 0.001 * w.max())\n",
    "        \n",
    "        # RBF-IMA inf\n",
    "        clf = RBF_IMA(n_neurons=p, eta=eta, lambda_param=lambda_param[2], delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000, p='inf')\n",
    "        clf.centers = centers\n",
    "        iterations_IMA_pinf[i], updates_pinf[i], iterations_FMP_pinf[i], margin = clf.fit(X_train, y_train)\n",
    "        margins.append(margin)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_RBF_pinf[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_RBF_pinf[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_RBF_pinf[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_RBF_pinf_1[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_RBF_pinf_2[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_RBF_pinf_3[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_RBF_pinf_4[i] = L0_norm(w, 0.001 * w.max())\n",
    "\n",
    "        # RBF-IMA 1\n",
    "        clf = RBF_IMA(n_neurons=p, eta=eta, lambda_param=lambda_param[0], delta_margin=10^-3, IMA_iterations=IMA_iterations, max_updates=10000, p='1')\n",
    "        clf.centers = centers\n",
    "        iterations_IMA_p1[i], updates_p1[i], iterations_FMP_p1[i], margin = clf.fit(X_train, y_train)\n",
    "        margins.append(margin)\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = True)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = True)\n",
    "        margin_IM_RBF_p1[i] = compute_margin(clf.H[:,:], y_train, clf.w, clf.b)\n",
    "        train_accuracy_IM_RBF_p1[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_IM_RBF_p1[i] = accuracy_score(y_test, y_hat)\n",
    "        w = clf.w\n",
    "        norm_w = LA.norm(w, ord=2)\n",
    "        w = w/norm_w\n",
    "        norm_L0_IM_RBF_p1_1[i] = L0_norm(w, 0.2 * w.max())\n",
    "        norm_L0_IM_RBF_p1_2[i] = L0_norm(w, 0.1 * w.max())\n",
    "        norm_L0_IM_RBF_p1_3[i] = L0_norm(w, 0.01 * w.max())\n",
    "        norm_L0_IM_RBF_p1_4[i] = L0_norm(w, 0.001 * w.max())\n",
    "\n",
    "                \n",
    "        # RBF\n",
    "        y_hat=clf.predict(X_test, use_IMA_w = False)\n",
    "        y_hat_train=clf.predict(X_train, use_IMA_w = False)\n",
    "        margin_RBF[i] = compute_margin(clf.H[:,:], y_train, clf.w_rbf, 0)\n",
    "        train_accuracy_RBF[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_RBF[i] = accuracy_score(y_test, y_hat)\n",
    "        i+=1\n",
    "        \n",
    "    print(\"********* Results RBF-IMA p=2 **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_RBF_p2.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_RBF_p2.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_RBF_p2.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_RBF_p2.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA_p2.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA_p2.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates_p2.mean())+ \"+/-\" + '{:.4f}'.format(updates_p2.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_RBF_p2.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_RBF_p2.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p2_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p2_1.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p2_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p2_2.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p2_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p2_3.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p2_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p2_4.std()))\n",
    "\n",
    "    print(\"********* Results RBF-IMA p=1 **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_RBF_p1.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_RBF_p1.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_RBF_p1.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_RBF_p1.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA_p1.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA_p1.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates_p1.mean())+ \"+/-\" + '{:.4f}'.format(updates_p1.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_RBF_p1.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_RBF_p1.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p1_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p1_1.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p1_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p1_2.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p1_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p1_3.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_p1_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_p1_4.std()))\n",
    "\n",
    "    print(\"********* Results RBF-IMA p=inf **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_IM_RBF_pinf.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_IM_RBF_pinf.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_IM_RBF_pinf.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_IM_RBF_pinf.std()))\n",
    "    print(\"Iterations IMA: \" + '{:.4f}'.format(iterations_IMA_pinf.mean())+ \"+/-\" + '{:.4f}'.format(iterations_IMA_pinf.std()))\n",
    "    print(\"Updates: \" + '{:.4f}'.format(updates_pinf.mean())+ \"+/-\" + '{:.4f}'.format(updates_pinf.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_IM_RBF_pinf.mean())+ \"+/-\" + '{:.9f}'.format(margin_IM_RBF_pinf.std()))\n",
    "    print(\"Norm L0 (20%): \" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_1.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_1.std()))\n",
    "    print(\"Norm L0 (10%): \" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_2.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_2.std()))\n",
    "    print(\"Norm L0 (1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_3.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_3.std()))\n",
    "    print(\"Norm L0 (0.1%): \" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_4.mean())+ \"+/-\" + '{:.9f}'.format(norm_L0_IM_RBF_pinf_4.std()))\n",
    "    \n",
    "    \n",
    "    print(\"********* Results RBF **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_RBF.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_RBF.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_RBF.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_RBF.std()))\n",
    "    print(\"Margin: \" + '{:.9f}'.format(margin_RBF.mean())+ \"+/-\" + '{:.9f}'.format(margin_RBF.std()))    \n",
    "    return margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_l(X, y, p):\n",
    "    # GridSearch for lambda and learning rate of IMA ELM\n",
    "    parameters = {'lambda_param':[0.01, 0.1, 1, 10, 100]}\n",
    "    clf_1 = RBF_IMA(n_neurons=p, delta_margin=10^-3, IMA_iterations=20, max_updates=10000, p=\"1\")\n",
    "    clf_1 = GridSearchCV(clf_1, parameters, scoring='accuracy', cv=10, verbose=0)\n",
    "    clf_1.fit(X, y)\n",
    "\n",
    "    clf_2 = RBF_IMA(n_neurons=p, delta_margin=10^-3, IMA_iterations=20, max_updates=10000, p=\"2\")\n",
    "    clf_2 = GridSearchCV(clf_2, parameters, scoring='accuracy', cv=10, verbose=0)\n",
    "    clf_2.fit(X, y)\n",
    "\n",
    "    clf_inf = RBF_IMA(n_neurons=p, delta_margin=10^-3, IMA_iterations=20, max_updates=10000, p=\"inf\")\n",
    "    clf_inf = GridSearchCV(clf_inf, parameters, scoring='accuracy', cv=10, verbose=0)\n",
    "    clf_inf.fit(X, y)\n",
    "\n",
    "    return [clf_1.best_params_['lambda_param'], clf_2.best_params_['lambda_param'], clf_inf.best_params_['lambda_param']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(X,y):\n",
    "    # Normalizing data:\n",
    "    X = preprocessing.normalize(X, axis=0)\n",
    "    #C = grid_C(X, y)\n",
    "    n = len(X)\n",
    "    if n>1000:\n",
    "        n=1000\n",
    "    for p in [int(n/3), int(n/5), int(n/7)]:\n",
    "        l = grid_l(X, y, p=p)\n",
    "        print(f\"Experimento com {p} neurônios:\" )\n",
    "        m = results(X, y, n_splits=10, p=p, eta=0.1, IMA_iterations=20, lambda_param=l)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IRIS\")\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "# setosa - 0, versicolor - 1, virginica - 2  \n",
    "y = iris.target \n",
    "# O problema agora possui apenas as classes y=-1 e y=1\n",
    "y[y>0] = 1\n",
    "y[y==0] = -1\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SYNTHETIC\")\n",
    "synthetic_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/synthetic_dataset/synthetic_control.data', sep=\"\\s+\",  header=None, engine='python')\n",
    "X = synthetic_dataset.to_numpy()\n",
    "y = np.concatenate((np.ones(100), np.ones(200)*-1, np.ones(100), np.ones(100)*-1,np.ones(100)))\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IONOSPHERE\")\n",
    "ionosphere_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/Ionosphere/ionosphere.data', names=list(range(0,35)), sep=',')\n",
    "y = ionosphere_dataset[34].to_numpy()\n",
    "X = ionosphere_dataset.drop([34], axis='columns').to_numpy()\n",
    "y[np.where(y=='g')] = 1\n",
    "y[np.where(y=='b')] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WINE\")\n",
    "wine_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/wine/wine.data', names=['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315', 'Proline'])\n",
    "# convert to array\n",
    "y = wine_dataset[['Class']].to_numpy()\n",
    "X = wine_dataset.drop(\"Class\",axis='columns').to_numpy()\n",
    "y[np.where(y==3)] = 1\n",
    "y[np.where(y==2)] = -1\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WDBC\")\n",
    "wdbc_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/WDBC/wdbc.data', names=list(range(0,32)))\n",
    "# convert to array\n",
    "y = wdbc_dataset[1].to_numpy()\n",
    "X = wdbc_dataset.drop([0, 1],axis='columns').to_numpy()\n",
    "y[np.where(y=='B')] = 1\n",
    "y[np.where(y=='M')] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SONAR\")\n",
    "sonar_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/sonar/sonar.all-data', names=list(range(0,61)), sep=',')\n",
    "y = sonar_dataset[60].to_numpy()\n",
    "X = sonar_dataset.drop([60], axis='columns').to_numpy()\n",
    "y[np.where(y=='R')] = 1\n",
    "y[np.where(y=='M')] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DIABETES\")\n",
    "pima_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/diabetes/diabetes.csv', sep=\",\", engine='python')\n",
    "y = pima_dataset['Outcome'].to_numpy()\n",
    "X = pima_dataset.drop(['Outcome'], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HEART\")\n",
    "statlog_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/statlog/heart.dat', sep=\" \", header=None, engine='python')\n",
    "y = statlog_dataset[13].to_numpy()\n",
    "X = statlog_dataset.drop([13], axis='columns').to_numpy()\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HABERMAN\")\n",
    "haberman = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/haberman/haberman.data', sep=\",\", header=None, engine='python')\n",
    "y = haberman[3].to_numpy()\n",
    "X = haberman.drop([3], axis='columns').to_numpy()\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRANSFUSION\")\n",
    "transfusion = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/transfusion/transfusion.data', sep=\",\", engine='python')\n",
    "y = transfusion[\"whether he/she donated blood in March 2007\"].to_numpy()\n",
    "X = transfusion.drop([\"whether he/she donated blood in March 2007\"], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUSTRALIAN\")\n",
    "australian = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/australian_credit/australian.dat', header=None, sep=\" \", engine='python')\n",
    "australian = australian.replace(\"?\", np.nan)\n",
    "australian = australian.dropna()\n",
    "y = australian[14].to_numpy()\n",
    "X = australian.drop([14], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BREAST\")\n",
    "breast = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/breast/breast.data', header=None, sep=\",\", engine='python')\n",
    "breast = breast.replace(\"?\", np.nan)\n",
    "breast = breast.dropna()\n",
    "y = breast[10].to_numpy()\n",
    "X = breast.drop([0, 10], axis='columns').to_numpy()\n",
    "y[np.where(y==4)] = 1\n",
    "y[np.where(y==2)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset:\n",
    "print(\"GLASS\")\n",
    "headers = [\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"Class\"]\n",
    "df = pd.read_csv(\"~/Documents/UFMG/Graduation/10/Reconhecimento de padrões/list/pattern-recognition-exercises/list_5/databases/glass.csv\", names = headers)\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "X = X.drop(\"Id\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "y[np.where(y>1)] = -1\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in banknote authentication set\n",
    "print(\"BANKNOTE\")\n",
    "banknotes = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/banknote/data_banknote_authentication.txt', names=['variance', 'skewness', 'curtosis', 'entropy', 'class'])\n",
    "# convert to array\n",
    "X = banknotes[['variance', 'skewness', 'curtosis', 'entropy']].to_numpy()\n",
    "y = banknotes[['class']].to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MUSHROOM\")\n",
    "df = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/Mushroom/agaricus-lepiota.data', delimiter =',', header=None)\n",
    "df = df.replace(\"?\", np.nan) \n",
    "df = df.dropna() \n",
    "y = df[0].to_numpy()\n",
    "X = df.drop([0], axis='columns')\n",
    "X = pd.get_dummies(X).to_numpy()\n",
    "y[np.where(y=='e')] = -1\n",
    "y[np.where(y=='p')] = 1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROBOT\")\n",
    "robot_dataset = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/robot/lp4_data.csv', delimiter =',')\n",
    "X = robot_dataset.to_numpy().reshape([117,90])\n",
    "y = np.concatenate((np.ones(24), np.ones(117-24)*-1))\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAMMOGRAPHIC\")\n",
    "mammo = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/mammographic/mammographic_masses.data', sep=\",\", header=None, engine='python')\n",
    "mammo = mammo.replace(\"?\", np.nan)\n",
    "mammo = mammo.dropna()\n",
    "y = mammo[5].to_numpy()\n",
    "X = mammo.drop([5], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SPAM\")\n",
    "spam = pd.read_csv('~/Documents/UFMG/Mastering/article/data sets/spam/spambase.data', header=None, sep=\",\", engine='python')\n",
    "y = spam[57].to_numpy()\n",
    "X = spam.drop([57], axis='columns').to_numpy()\n",
    "y[np.where(y==0)] = -1\n",
    "y = np.array(y.tolist())\n",
    "run(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k39",
   "language": "python",
   "name": "k39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
